{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install - U pip setuptools wheel\n",
    "%pip install tqdm\n",
    "%pip install torch torchvision torchaudio\n",
    "!export CUDA_PATH = \"/opt/nvidia/cuda\"\n",
    "%pip install - U spacy[cuda11X, transformers]\n",
    "%pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 10:46:31.438359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 10:46:32.133322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-09 10:46:32.133391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-09 10:46:32.133402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-09 10:46:32.825240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 10:46:32.825606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 10:46:32.825762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_lg -qq\n",
    "!python3 -m spacy download en_core_web_trf -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 15:44:08.466311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 15:44:10.098792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 15:44:10.099163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 15:44:10.099313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, jaccard_score\n",
    "\n",
    "with open('selected_tags.json', 'r') as openfile:\n",
    "    selected_tags = json.load(openfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_train = pd.read_csv(\n",
    "    './train.csv', converters={'tag_set': eval, 'tag_list': eval})\n",
    "sample_test = pd.read_csv(\n",
    "    './test.csv', converters={'tag_set': eval, 'tag_list': eval})\n",
    "sample_validation = pd.read_csv(\n",
    "    './validation.csv', converters={'tag_set': eval, 'tag_list': eval})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use the GPU, with memory allocations directed via PyTorch.\n",
    "# This prevents out-of-memory errors that would otherwise occur from competing\n",
    "# memory pools.\n",
    "set_gpu_allocator(\"pytorch\")\n",
    "require_gpu(0)\n",
    "\n",
    "\n",
    "def preprocess(texts, nlp):\n",
    "    removal = ['ADV', 'PRON', 'CCONJ', 'PUNCT',\n",
    "               'PART', 'DET', 'ADP', 'SPACE', 'NUM', 'SYM']\n",
    "    tokens = []\n",
    "    cleaned_texts = []\n",
    "    print(\"preprocessing\")\n",
    "    for summary in tqdm(nlp.pipe(texts, disable=[\"tok2vec\"]), total=len(texts)):\n",
    "        question_tokens = []\n",
    "        for token in summary:\n",
    "            if token.pos_ not in removal and not token.is_stop and token.is_alpha:\n",
    "                question_tokens.append(token.lemma_)\n",
    "        cleaned_texts.append(\" \".join(question_tokens))\n",
    "    # question_tokens = [token.lemma_ for token in summary if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "    return cleaned_texts\n",
    "\n",
    "def preprocess_transformers(texts, nlp):\n",
    "    tokens = []\n",
    "    removal = [ 'PUNCT', 'SPACE', 'NUM', 'SYM']\n",
    "    cleaned_texts = []\n",
    "    print(\"preprocessing\")\n",
    "    for summary in tqdm(nlp.pipe(texts, disable=[\"transformer\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"]), total=len(texts)):\n",
    "        question_tokens = []\n",
    "        for token in summary:\n",
    "            if token.pos_ not in removal and token.is_alpha and len(question_tokens)<512:\n",
    "                question_tokens.append(token.lower_)\n",
    "        cleaned_texts.append(\" \".join(question_tokens))\n",
    "    # question_tokens = [token.lemma_ for token in summary if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "    return cleaned_texts\n",
    "\n",
    "\n",
    "def convert(data, outfile, nlp):\n",
    "    db = spacy.tokens.DocBin()\n",
    "    docs = []\n",
    "    print(\"converting\")\n",
    "    for doc, labels in tqdm(nlp.pipe(data.values, as_tuples=True), total=len(data)):\n",
    "        for tag in selected_tags:\n",
    "            doc.cats[tag] = tag in labels\n",
    "        db.add(doc)\n",
    "    db.to_disk(outfile)\n",
    "\n",
    "def evaluate_predictions(pred, mlb):\n",
    "    print(\"Roc auc for each tag:\")\n",
    "    print(list(zip(mlb.classes_, roc_auc_score(y, pred, average=None))))\n",
    "    print(\n",
    "        f\"Text roc auc macro average: {roc_auc_score(y, pred, average='macro')}\")\n",
    "    print(\n",
    "        f\"Jaccard score sample average: {jaccard_score(y, pred, average='samples')}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1c886c0b29443ba24876ee520b8f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7432fe13e4834bb2bfa03ff207951426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f274e16423144e2b9bd40eb161654c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4830e6e1ecb47b2a0cf11a511ce8c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765ed862c082463f8393599e4b80d2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de583767f70f474cac515b24225d6c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.text.isna()].loc[:]\n",
    "train_df[\"text_processed\"] = preprocess(train_df.text, nlp)\n",
    "convert(train_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_train_bow.spacy', nlp)\n",
    "test_df = sample_test[~sample_test.text.isna()].loc[:]\n",
    "test_df[\"text_processed\"] = preprocess(test_df.text, nlp)\n",
    "convert(test_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_test_bow.spacy', nlp)\n",
    "validation_df = sample_validation[~sample_validation.text.isna()].loc[:]\n",
    "validation_df[\"text_processed\"] = preprocess(\n",
    "    validation_df.text, nlp)\n",
    "convert(validation_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_validation_bow.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 12:18:13.716779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 12:18:15.191947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:18:15.192320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:18:15.192476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_BOW\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 12:18:19,278] [INFO] Set up nlp object from config\n",
      "[2023-03-17 12:18:19,903] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 12:18:19,906] [INFO] Created vocabulary\n",
      "[2023-03-17 12:18:21,924] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 12:18:23,337] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 12:19:07,372] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_121908-yixyk8wd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mautumn-flower-40\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/yixyk8wd\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       54.94    0.55\n",
      "  0     200          24.56       57.63    0.58\n",
      "  0     400          18.37       61.71    0.62\n",
      "  0     600          16.40       66.07    0.66\n",
      "  0     800          16.69       70.49    0.70\n",
      "  0    1000          15.45       74.75    0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 57.8s\n",
      "  0    1200          14.50       77.78    0.78\n",
      "  0    1400          13.89       80.89    0.81\n",
      "  0    1600          13.25       83.26    0.83\n",
      "  0    1800          12.33       85.22    0.85\n",
      "  0    2000          12.37       86.85    0.87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 45.7s\n",
      "  0    2200          11.96       88.07    0.88\n",
      "  0    2400          11.34       89.10    0.89\n",
      "  0    2600          11.05       89.82    0.90\n",
      "  0    2800          10.93       90.21    0.90\n",
      "  0    3000          10.55       90.65    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 63.5s\n",
      "  0    3200          10.40       91.15    0.91\n",
      "  0    3400          10.36       91.45    0.91\n",
      "  0    3600          10.34       91.65    0.92\n",
      "  0    3800           9.93       91.82    0.92\n",
      "  0    4000          10.10       92.03    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 58.2s\n",
      "  0    4200           9.80       92.15    0.92\n",
      "  0    4400           9.95       92.31    0.92\n",
      "  0    4600           9.77       92.46    0.92\n",
      "  0    4800           9.58       92.62    0.93\n",
      "  0    5000           9.68       92.58    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 51.0s\n",
      "  0    5200           9.48       92.69    0.93\n",
      "  0    5400           9.52       92.83    0.93\n",
      "  0    5600           9.49       92.80    0.93\n",
      "  0    5800           9.21       92.87    0.93\n",
      "  0    6000           9.30       93.00    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 68.0s\n",
      "  0    6200           9.30       93.04    0.93\n",
      "  0    6400           9.42       93.04    0.93\n",
      "  1    6600           9.49       93.14    0.93\n",
      "  1    6800           7.94       93.09    0.93\n",
      "  1    7000           8.22       93.09    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 60.5s\n",
      "  1    7200           8.23       93.08    0.93\n",
      "  1    7400           8.16       93.07    0.93\n",
      "  1    7600           8.30       93.10    0.93\n",
      "  1    7800           8.12       93.04    0.93\n",
      "  1    8000           8.13       93.10    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 38.4s\n",
      "  1    8200           8.13       93.09    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc ▁▁▂▃▄▅▅▆▆▇▇▇▇▇▇█████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f ▂▁▁▁▂▃▄▄▅▆▆▆▇▇▇▇▇▇▇▇████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p ▁▁▅█▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r ▃▁▁▁▂▂▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f ▃▁▁▁▂▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p ▁█▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r ▃▁▁▁▂▃▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇██▇███████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score ▁▁▂▃▄▅▅▆▆▇▇▇▇▇▇█████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel ▁█▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score ▁▁▂▃▄▅▅▆▆▇▇▇▇▇▇█████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed █▄▁▂▃▄▁▇▄▄▅▃█▇▅▄▄▆▆▇▄▃█▄▄▅▄▆▆▄▃▆▅▂▃▅▁▄▂▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.93086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.62274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.78301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.5212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.62599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.7812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.52223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.93086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 8.13347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.93086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 126136.12951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mautumn-flower-40\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/yixyk8wd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 80 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_121908-yixyk8wd/logs\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_BOW/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_BOW.cfg --output ./output_BOW --paths.train ./text_train_bow.spacy --paths.dev ./text_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34edc8b0ea1c4f81a9e59647fbb47d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef5a97aa7074e40a7e7987c500c0c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cd694b5bc34de0b4e1a4c5f187d4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6bb1f4854f43faa30deedbdfb44dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb7c17e0b44dd780cc6747fab4ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161cce72dec748eba5309a2e0c555162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.code.isna()].loc[:]\n",
    "train_df[\"code_processed\"] = preprocess(train_df.code, nlp)\n",
    "convert(train_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_train_bow.spacy', nlp)\n",
    "test_df = sample_test[~sample_test.code.isna()].loc[:]\n",
    "test_df[\"code_processed\"] = preprocess(test_df.code, nlp)\n",
    "convert(test_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_test_bow.spacy', nlp)\n",
    "validation_df = sample_validation[~sample_validation.code.isna()].loc[:]\n",
    "validation_df[\"code_processed\"] = preprocess(\n",
    "    validation_df.code, nlp)\n",
    "convert(validation_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_validation_bow.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 13:35:08.530678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 13:35:10.172390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:35:10.172770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:35:10.172917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_code_BOW\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 13:35:14,175] [INFO] Set up nlp object from config\n",
      "[2023-03-17 13:35:14,738] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 13:35:14,741] [INFO] Created vocabulary\n",
      "[2023-03-17 13:35:16,832] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 13:35:18,311] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 13:35:53,999] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_133555-pjfmqgkv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgentle-thunder-43\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/pjfmqgkv\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       51.55    0.52\n",
      "  0     200          28.70       66.91    0.67\n",
      "  0     400          19.49       71.67    0.72\n",
      "  0     600          17.49       75.55    0.76\n",
      "  0     800          16.50       78.86    0.79\n",
      "  0    1000          14.75       81.13    0.81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 28.4s\n",
      "  0    1200          13.57       82.89    0.83\n",
      "  0    1400          13.80       84.41    0.84\n",
      "  0    1600          12.52       85.91    0.86\n",
      "  0    1800          12.07       86.99    0.87\n",
      "  0    2000          11.76       87.73    0.88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 71.3s\n",
      "  0    2200          11.37       88.32    0.88\n",
      "  0    2400          11.02       88.95    0.89\n",
      "  0    2600          11.00       89.40    0.89\n",
      "  0    2800          10.88       89.88    0.90\n",
      "  0    3000          10.80       90.22    0.90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 80.1s\n",
      "  0    3200          10.74       90.45    0.90\n",
      "  0    3400          10.44       90.59    0.91\n",
      "  0    3600          10.47       90.72    0.91\n",
      "  0    3800          10.47       90.94    0.91\n",
      "  0    4000          10.11       90.95    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 51.8s\n",
      "  0    4200          10.33       91.15    0.91\n",
      "  0    4400          10.06       91.20    0.91\n",
      "  0    4600          10.14       91.31    0.91\n",
      "  0    4800           9.88       91.32    0.91\n",
      "  1    5000           9.16       91.40    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 72.5s\n",
      "  1    5200           8.97       91.40    0.91\n",
      "  1    5400           8.88       91.43    0.91\n",
      "  1    5600           8.83       91.38    0.91\n",
      "  1    5800           9.11       91.36    0.91\n",
      "  1    6000           9.02       91.37    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 56.3s\n",
      "  1    6200           8.74       91.45    0.91\n",
      "  1    6400           8.96       91.46    0.91\n",
      "  1    6600           8.96       91.40    0.91\n",
      "  1    6800           8.97       91.39    0.91\n",
      "  1    7000           8.89       91.45    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 92.8s\n",
      "  1    7200           8.96       91.35    0.91\n",
      "  1    7400           8.94       91.41    0.91\n",
      "  1    7600           8.82       91.45    0.91\n",
      "  1    7800           9.27       91.46    0.91\n",
      "  1    8000           8.91       91.49    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 74.3s\n",
      "  1    8200           9.00       91.48    0.91\n",
      "  2    8400           7.86       91.49    0.91\n",
      "  2    8600           7.94       91.48    0.91\n",
      "  2    8800           8.08       91.50    0.92\n",
      "  2    9000           8.26       91.50    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 62.5s\n",
      "  2    9200           8.02       91.41    0.91\n",
      "  2    9400           8.11       91.42    0.91\n",
      "  2    9600           8.49       91.39    0.91\n",
      "  2    9800           8.02       91.48    0.91\n",
      "  2   10000           8.29       91.41    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 44.8s\n",
      "  2   10200           8.41       91.43    0.91\n",
      "  2   10400           8.07       91.36    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 6241.985 MB of 6241.985 MB uploaded (5473.753 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc ▁▄▅▆▆▆▇▇▇███████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f ▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r ▁▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f ▁▁▂▄▅▅▆▆▆▇▇▇▇▇▇▇▇███████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r ▁▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score ▁▄▅▆▆▆▇▇▇███████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel ▁█▆▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score ▁▄▅▆▆▆▇▇▇███████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed ▆▄▆▅▄▆▇▇█▇▇▆▄▅▄▅▅▄▅▅▄▄▄▅▅▄▅▂▆▅▁▄▄▆▇▇▄▄▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.91359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.59129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.77576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.48201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.60022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.77825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.48848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.91359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 8.07295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.91359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 107350.40416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgentle-thunder-43\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/pjfmqgkv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 100 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_133555-pjfmqgkv/logs\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_code_BOW/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_BOW.cfg --output ./output_code_BOW --paths.train ./code_train_bow.spacy --paths.dev ./code_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tok2Vec\n",
    "\n",
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 12:20:20.144707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 12:20:21.668324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:20:21.671812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:20:21.671976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_tok2vec\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 12:20:26,230] [INFO] Set up nlp object from config\n",
      "[2023-03-17 12:20:26,836] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 12:20:26,840] [INFO] Created vocabulary\n",
      "[2023-03-17 12:20:29,539] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 12:20:31,331] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 12:21:16,823] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_122118-r70w9wfk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-pond-41\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/r70w9wfk\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.32       48.97    0.49\n",
      "  0     200          18.07       57.48    0.57\n",
      "  0     400          18.30       63.25    0.63\n",
      "  0     600          16.82       69.07    0.69\n",
      "  0     800          16.68       75.60    0.76\n",
      "  0    1000          15.24       80.69    0.81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 77.1s\n",
      "  0    1200          14.59       82.89    0.83\n",
      "  0    1400          14.07       85.01    0.85\n",
      "  0    1600          13.50       86.39    0.86\n",
      "  0    1800          12.69       87.63    0.88\n",
      "  0    2000          12.69       88.68    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 70.2s\n",
      "  0    2200          12.32       89.43    0.89\n",
      "  0    2400          11.57       90.33    0.90\n",
      "  0    2600          11.42       90.74    0.91\n",
      "  0    2800          11.22       90.90    0.91\n",
      "  0    3000          11.03       91.39    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 72.7s\n",
      "  0    3200          10.70       91.59    0.92\n",
      "  0    3400          10.80       91.79    0.92\n",
      "  0    3600          10.73       92.02    0.92\n",
      "  0    3800          10.35       92.03    0.92\n",
      "  0    4000          10.41       91.88    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 87.8s\n",
      "  0    4200          10.23       92.37    0.92\n",
      "  0    4400          10.30       92.29    0.92\n",
      "  0    4600          10.03       92.43    0.92\n",
      "  0    4800           9.99       92.46    0.92\n",
      "  0    5000          10.15       92.48    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 66.8s\n",
      "  0    5200           9.74       92.70    0.93\n",
      "  0    5400           9.84       92.90    0.93\n",
      "  0    5600           9.88       92.84    0.93\n",
      "  0    5800           9.70       92.92    0.93\n",
      "  0    6000           9.72       92.92    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 58.3s\n",
      "  0    6200           9.83       93.06    0.93\n",
      "  0    6400           9.72       93.15    0.93\n",
      "  1    6600           9.78       93.23    0.93\n",
      "  1    6800           8.95       93.05    0.93\n",
      "  1    7000           9.25       93.19    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 45.5s\n",
      "  1    7200           9.15       93.29    0.93\n",
      "  1    7400           9.13       93.46    0.93\n",
      "  1    7600           9.22       93.30    0.93\n",
      "  1    7800           9.15       93.34    0.93\n",
      "  1    8000           9.14       93.48    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 34.0s\n",
      "  1    8200           9.09       93.28    0.93\n",
      "  1    8400           9.36       93.43    0.93\n",
      "  1    8600           8.83       93.63    0.94\n",
      "  1    8800           9.12       93.65    0.94\n",
      "  1    9000           9.29       93.59    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 8.0s\n",
      "  1    9200           9.21       93.49    0.93\n",
      "  1    9400           9.34       93.52    0.94\n",
      "  1    9600           9.14       93.68    0.94\n",
      "  1    9800           8.98       93.62    0.94\n",
      "  1   10000           9.26       93.60    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 5.8s\n",
      "  1   10200           9.18       93.80    0.94\n",
      "  1   10400           8.98       93.63    0.94\n",
      "  1   10600           9.00       93.80    0.94\n",
      "  1   10800           9.01       93.81    0.94\n",
      "  1   11000           9.11       93.64    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.9s\n",
      "  1   11200           8.86       93.76    0.94\n",
      "  1   11400           8.80       93.93    0.94\n",
      "  1   11600           8.95       93.85    0.94\n",
      "  2   11800           8.96       93.77    0.94\n",
      "  2   12000           8.38       93.99    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.8s\n",
      "  2   12200           8.64       93.91    0.94\n",
      "  2   12400           8.44       93.80    0.94\n",
      "  2   12600           8.64       93.79    0.94\n",
      "  2   12800           8.57       93.90    0.94\n",
      "  2   13000           8.49       93.86    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 4.5s\n",
      "  2   13200           8.91       94.01    0.94\n",
      "  2   13400           8.55       93.87    0.94\n",
      "  2   13600           8.60       93.94    0.94\n",
      "  2   13800           8.64       93.92    0.94\n",
      "  2   14000           8.68       94.07    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.9s\n",
      "  2   14200           8.65       94.12    0.94\n",
      "  2   14400           8.58       93.98    0.94\n",
      "  2   14600           8.54       93.94    0.94\n",
      "  2   14800           9.02       93.97    0.94\n",
      "  2   15000           8.63       94.08    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.6s\n",
      "  2   15200           8.63       93.98    0.94\n",
      "  2   15400           8.85       94.09    0.94\n",
      "  2   15600           8.48       94.19    0.94\n",
      "  2   15800           8.56       94.10    0.94\n",
      "  2   16000           8.56       94.23    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.9s\n",
      "  2   16200           8.47       94.11    0.94\n",
      "  2   16400           8.55       94.14    0.94\n",
      "  2   16600           8.64       94.31    0.94\n",
      "  2   16800           8.71       94.20    0.94\n",
      "  3   17000           8.09       94.25    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.5s\n",
      "  3   17200           8.06       94.10    0.94\n",
      "  3   17400           8.15       94.21    0.94\n",
      "  3   17600           7.89       94.22    0.94\n",
      "  3   17800           7.93       94.24    0.94\n",
      "  3   18000           8.34       94.21    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.6s\n",
      "  3   18200           7.93       94.18    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc ▁▃▅▇▇▇▇█████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f ▂▁▂▄▅▆▇▇▇▇▇▇▇███████▇███████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p ▁▃▆▇▇▇▇▇██████▇█▇███████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r ▄▁▁▃▅▅▆▇▆▇▇▇▇█▇██▇█▇▇██▇▇███████▇█▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f ▂▁▂▄▆▆▇▇▇▇▇▇▇███████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p ▁▄▇▇▇▇▇▇▇████▇▇▇▇█▇██▇██████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r ▄▁▁▃▅▅▆▇▇▇▇▇▇█▇██▇█▇▇██▇▇███████▇█▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score ▁▃▅▇▇▇▇█████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel ▁█▇▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score ▁▃▅▇▇▇▇█████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed ▄▃▇▇▇▇▇▁▇▆▇▆▆▆▇▆▇█▆▇▁█▇█▇█▇█▇▇▇█▁▇▇██▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.94185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.65763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.76584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.58133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.65988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.76398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.58074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.94185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 7.93265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.94185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 94456.27158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfearless-pond-41\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/r70w9wfk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 180 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_122118-r70w9wfk/logs\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_tok2vec/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_tok2vec.cfg --output ./output_tok2vec --paths.train ./text_train_bow.spacy --paths.dev ./text_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 13:34:36.026104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 13:34:37.612346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:34:37.612711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:34:37.612871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_code_tok2vec\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 13:34:42,731] [INFO] Set up nlp object from config\n",
      "[2023-03-17 13:34:43,319] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 13:34:43,322] [INFO] Created vocabulary\n",
      "[2023-03-17 13:34:45,466] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 13:34:46,990] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 13:35:22,916] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_133524-x7mll9zs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-salad-42\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/x7mll9zs\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.23       48.30    0.48\n",
      "  0     200          19.16       62.65    0.63\n",
      "  0     400          16.50       71.57    0.72\n",
      "  0     600          15.38       77.15    0.77\n",
      "  0     800          15.09       80.80    0.81\n",
      "  0    1000          13.70       82.69    0.83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 37.5s\n",
      "  0    1200          12.48       83.16    0.83\n",
      "  0    1400          12.50       84.53    0.85\n",
      "  0    1600          11.74       85.02    0.85\n",
      "  0    1800          11.48       85.80    0.86\n",
      "  0    2000          11.67       85.91    0.86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 86.6s\n",
      "  0    2200          11.16       86.86    0.87\n",
      "  0    2400          10.71       87.50    0.88\n",
      "  0    2600          10.58       88.31    0.88\n",
      "  0    2800          10.62       88.67    0.89\n",
      "  0    3000          10.48       88.81    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 58.7s\n",
      "  0    3200          10.49       89.17    0.89\n",
      "  0    3400          10.27       89.21    0.89\n",
      "  0    3600          10.21       89.35    0.89\n",
      "  0    3800          10.27       89.65    0.90\n",
      "  0    4000          10.04       90.07    0.90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 69.5s\n",
      "  0    4200           9.88       90.27    0.90\n",
      "  0    4400           9.83       90.20    0.90\n",
      "  0    4600           9.79       90.72    0.91\n",
      "  0    4800           9.60       90.79    0.91\n",
      "  1    5000           8.93       90.96    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 82.7s\n",
      "  1    5200           9.20       90.63    0.91\n",
      "  1    5400           8.94       90.79    0.91\n",
      "  1    5600           9.17       90.77    0.91\n",
      "  1    5800           9.21       91.10    0.91\n",
      "  1    6000           9.16       91.11    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 59.7s\n",
      "  1    6200           8.90       91.35    0.91\n",
      "  1    6400           8.97       91.24    0.91\n",
      "  1    6600           9.10       91.42    0.91\n",
      "  1    6800           9.09       91.61    0.92\n",
      "  1    7000           9.08       91.56    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 96.3s\n",
      "  1    7200           9.03       91.33    0.91\n",
      "  1    7400           9.04       91.48    0.91\n",
      "  1    7600           9.13       91.53    0.92\n",
      "  1    7800           9.07       91.55    0.92\n",
      "  1    8000           8.84       91.87    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 93.2s\n",
      "  1    8200           8.87       91.75    0.92\n",
      "  2    8400           8.20       92.04    0.92\n",
      "  2    8600           8.20       92.12    0.92\n",
      "  2    8800           8.33       91.98    0.92\n",
      "  2    9000           8.49       92.07    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 51.1s\n",
      "  2    9200           8.26       91.87    0.92\n",
      "  2    9400           8.33       92.11    0.92\n",
      "  2    9600           8.75       91.96    0.92\n",
      "  2    9800           8.37       92.33    0.92\n",
      "  2   10000           8.56       92.15    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 48.4s\n",
      "  2   10200           8.73       92.10    0.92\n",
      "  2   10400           8.51       92.00    0.92\n",
      "  2   10600           8.41       92.01    0.92\n",
      "  2   10800           8.57       92.28    0.92\n",
      "  2   11000           8.41       92.42    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 58.9s\n",
      "  2   11200           8.62       92.50    0.93\n",
      "  2   11400           8.47       92.50    0.93\n",
      "  3   11600           8.44       92.44    0.92\n",
      "  3   11800           7.97       92.39    0.92\n",
      "  3   12000           8.05       92.66    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 39.2s\n",
      "  3   12200           7.96       92.51    0.93\n",
      "  3   12400           7.73       92.60    0.93\n",
      "  3   12600           7.92       92.61    0.93\n",
      "  3   12800           7.86       92.71    0.93\n",
      "  3   13000           8.30       92.58    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 33.7s\n",
      "  3   13200           8.23       92.60    0.93\n",
      "  3   13400           8.10       92.46    0.92\n",
      "  3   13600           7.99       92.47    0.92\n",
      "  3   13800           8.06       92.52    0.93\n",
      "  3   14000           8.28       92.63    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 23.1s\n",
      "  3   14200           8.24       92.70    0.93\n",
      "  3   14400           8.10       92.63    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc ▁▃▆▆▇▇▇▇▇▇▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f ▁▁▃▅▆▆▆▇▇▇▇▇▇██▇▇███▇█████▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p ▁▃▆▇▇▇▇▇████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r ▄▁▃▅▅▆▆▆▆▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇█▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f ▁▁▄▅▆▆▇▇▇▇▇▇▇███▇███▇█████▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p ▁▄▆▇▇▇▇▇██████▇█████████████████████▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r ▄▁▃▅▅▅▆▆▆▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇█▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score ▁▃▆▆▇▇▇▇▇▇▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel ▁█▇▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score ▁▃▆▆▇▇▇▇▇▇▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed ▇█▅▇██▇▅█▆▇▇▇▆▄▇▆▇▅▇▇▇▇▆▄▅▇▆▁▄▄▅▄▇▇▅▄█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.92632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.62838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.75571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.55893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.64971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.75626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.56947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.92632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 8.09935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.92632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 90503.39666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mwise-salad-42\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/x7mll9zs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 140 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_133524-x7mll9zs/logs\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_code_tok2vec/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_tok2vec.cfg --output ./output_code_tok2vec --paths.train ./code_train_bow.spacy --paths.dev ./code_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBertA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /tmp/tmp0pknapxh/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmp0pknapxh/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5413/5413 [00:42<00:00, 127.96it/s]\n",
      "100%|██████████| 5322/5322 [01:00<00:00, 87.44it/s] \n"
     ]
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.text.isna()].loc[:]\n",
    "train_df[\"text_processed\"] = preprocess_transformers(train_df.text, nlp)\n",
    "test_df = sample_test[~sample_test.text.isna()].sample(\n",
    "    round(len(sample_test)/4))\n",
    "test_df[\"text_processed\"] = preprocess_transformers(\n",
    "    test_df.text, nlp)\n",
    "validation_df = sample_validation[~sample_validation.text.isna()].loc[:]\n",
    "validation_df[\"text_processed\"] = preprocess_transformers(\n",
    "    validation_df.text, nlp)\n",
    "convert(train_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_train_transformer.spacy', nlp)\n",
    "convert(test_df.loc[:, [\"text_processed\",\n",
    "        \"tag_list\"]], 'text_test_transformer.spacy', nlp)\n",
    "convert(validation_df.loc[:, [\n",
    "        \"text_processed\", \"tag_list\"]], 'text_validation_transformer.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:03:36.530246: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 16:03:38.978276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:03:38.978632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:03:38.978786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_transformer\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-16 16:03:44,086] [INFO] Set up nlp object from config\n",
      "[2023-03-16 16:03:44,762] [INFO] Pipeline: ['transformer', 'textcat_multilabel']\n",
      "[2023-03-16 16:03:44,765] [INFO] Created vocabulary\n",
      "[2023-03-16 16:03:44,767] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2023-03-16 16:04:56,451] [INFO] Initialized pipeline components: ['transformer', 'textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230316_160457-ogpumat3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfanciful-haze-34\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/ogpumat3\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  -------------  ----------  ------\n",
      "  0       0           0.00           0.28       47.91    0.48\n",
      "  0     200           3.77          70.76       85.01    0.85\n",
      "  0     400           2.11          44.35       88.98    0.89\n",
      "  0     600           2.23          39.66       90.51    0.91\n",
      "  0     800           2.03          35.19       91.21    0.91\n",
      "  0    1000           2.23          34.45       92.51    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.3s\n",
      "  0    1200           2.10          35.22       93.05    0.93\n",
      "  0    1400           2.05          33.39       93.20    0.93\n",
      "  0    1600           2.06          32.56       93.76    0.94\n",
      "  0    1800           1.89          31.59       93.98    0.94\n",
      "  0    2000           2.03          31.22       93.51    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.9s\n",
      "  0    2200           2.12          32.02       94.10    0.94\n",
      "  0    2400           2.10          30.57       94.44    0.94\n",
      "  0    2600           1.85          29.41       94.55    0.95\n",
      "  0    2800           2.06          30.23       94.55    0.95\n",
      "  0    3000           1.92          29.98       94.71    0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  0    3200           1.88          29.46       94.73    0.95\n",
      "  0    3400           1.99          30.93       94.67    0.95\n",
      "  0    3600           1.99          28.28       95.05    0.95\n",
      "  0    3800           2.02          29.01       94.86    0.95\n",
      "  0    4000           2.07          29.59       95.16    0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.9s\n",
      "  0    4200           1.94          28.87       95.10    0.95\n",
      "  0    4400           2.03          28.86       95.17    0.95\n",
      "  0    4600           1.97          28.41       95.22    0.95\n",
      "  0    4800           1.86          29.83       95.42    0.95\n",
      "  0    5000           2.02          28.35       95.29    0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  0    5200           2.12          29.23       95.36    0.95\n",
      "  0    5400           2.05          28.68       95.43    0.95\n",
      "  0    5600           1.93          27.78       95.55    0.96\n",
      "  0    5800           2.07          28.37       95.61    0.96\n",
      "  0    6000           1.90          27.20       95.77    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  1    6200           2.03          26.85       95.66    0.96\n",
      "  1    6400           1.86          26.06       95.85    0.96\n",
      "  1    6600           1.79          24.88       95.88    0.96\n",
      "  1    6800           1.85          25.58       95.74    0.96\n",
      "  1    7000           1.83          25.74       95.76    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  1    7200           1.91          25.89       95.88    0.96\n",
      "  1    7400           2.01          25.28       95.87    0.96\n",
      "  1    7600           1.72          24.80       95.80    0.96\n",
      "  1    7800           1.77          24.54       96.05    0.96\n",
      "  1    8000           1.92          25.91       96.00    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  1    8200           2.11          26.44       95.85    0.96\n",
      "  1    8400           1.77          25.99       96.00    0.96\n",
      "  1    8600           1.96          26.13       96.04    0.96\n",
      "  1    8800           1.75          25.36       96.04    0.96\n",
      "  1    9000           1.88          24.59       96.08    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.3s\n",
      "  1    9200           1.98          24.18       96.18    0.96\n",
      "  1    9400           1.85          24.51       96.23    0.96\n",
      "  1    9600           1.88          25.88       96.19    0.96\n",
      "  1    9800           1.92          24.52       96.19    0.96\n",
      "  1   10000           1.88          25.28       96.13    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  1   10200           1.91          24.71       96.30    0.96\n",
      "  1   10400           1.73          24.08       96.17    0.96\n",
      "  1   10600           1.88          24.69       96.18    0.96\n",
      "  1   10800           1.86          24.31       96.30    0.96\n",
      "  1   11000           1.83          23.93       96.30    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  1   11200           1.98          24.48       96.32    0.96\n",
      "  1   11400           1.87          24.74       96.30    0.96\n",
      "  1   11600           1.89          24.77       96.40    0.96\n",
      "  1   11800           1.98          25.97       96.48    0.96\n",
      "  1   12000           1.88          24.12       96.38    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  2   12200           1.78          23.45       96.47    0.96\n",
      "  2   12400           1.70          21.82       96.43    0.96\n",
      "  2   12600           1.79          22.13       96.43    0.96\n",
      "  2   12800           1.74          22.03       96.44    0.96\n",
      "  2   13000           1.64          20.37       96.41    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  2   13200           1.82          21.52       96.51    0.97\n",
      "  2   13400           1.75          21.37       96.42    0.96\n",
      "  2   13600           1.88          21.44       96.46    0.96\n",
      "  2   13800           1.73          21.25       96.51    0.97\n",
      "  2   14000           1.70          21.57       96.54    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  2   14200           1.67          22.28       96.60    0.97\n",
      "  2   14400           1.70          22.22       96.47    0.96\n",
      "  2   14600           1.93          22.26       96.56    0.97\n",
      "  2   14800           1.52          21.06       96.58    0.97\n",
      "  2   15000           1.64          21.97       96.59    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  2   15200           1.68          21.59       96.57    0.97\n",
      "  2   15400           1.75          21.54       96.60    0.97\n",
      "  2   15600           1.77          21.76       96.67    0.97\n",
      "  2   15800           1.70          20.66       96.62    0.97\n",
      "  2   16000           1.73          21.44       96.65    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  2   16200           1.77          20.71       96.72    0.97\n",
      "  2   16400           1.83          21.27       96.67    0.97\n",
      "  2   16600           1.77          21.01       96.71    0.97\n",
      "  2   16800           1.71          21.35       96.74    0.97\n",
      "  2   17000           1.76          20.40       96.72    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  2   17200           1.69          20.96       96.70    0.97\n",
      "  2   17400           1.57          20.62       96.74    0.97\n",
      "  2   17600           1.78          20.78       96.76    0.97\n",
      "  2   17800           1.61          20.22       96.78    0.97\n",
      "  2   18000           1.85          20.51       96.73    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  3   18200           1.72          20.36       96.74    0.97\n",
      "  3   18400           1.65          18.57       96.73    0.97\n",
      "  3   18600           1.75          18.57       96.75    0.97\n",
      "  3   18800           1.57          18.56       96.72    0.97\n",
      "  3   19000           1.56          17.43       96.72    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  3   19200           1.67          19.07       96.73    0.97\n",
      "  3   19400           1.50          19.57       96.74    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 9122.831 MB of 9122.852 MB uploaded (23.841 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc ▁▇▇▇████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f ▁▄▆▆▇▇▇▇▇▇▇▇▇█▇▇████▇███████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p ▁▆▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r ▅▁▃▄▅▆▅▆▇▆▆▇▆▇▆▆▇▇▇█▆▇▇▇▇█▇▇███▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f ▁▅▆▆▇▇▇▇▇▇▇▇▇█▇▇████▇███████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p ▁▇▇█▇▇██▇▇█▇█▇██████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r ▅▁▃▄▅▅▅▆▇▆▆▇▆▇▆▆▇▇▇█▆▇▇▇▇█▇▇▇██▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score ▁▇▇▇████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel ▁█▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer ▁███▇█████▇██▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▆▇▇▇▇▆▆▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score ▁▇▇▇████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed ▅▄▃▄▃▅▃▃▅▂▂▅▅▇▄▄▅▅▁▆██▅▄▄▃███████▅▆▇▅▄▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.96736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.74222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.76996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.7207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.73988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.75847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.72218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.96736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 19.57371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer 1.49791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.96736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 11345.44211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfanciful-haze-34\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/ogpumat3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 228 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230316_160457-ogpumat3/logs\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_transformer/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_transformer_filled.cfg --output ./output_transformer --paths.train ./text_train_transformer.spacy --paths.dev ./text_test_transformer.spacy --gpu-id 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81619/81619 [13:16<00:00, 102.47it/s]\n",
      " 21%|██        | 15681/76005 [01:55<07:08, 140.73it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 76005/76005 [09:12<00:00, 137.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.code.isna()].loc[:]\n",
    "train_df[\"code_processed\"] = preprocess_transformers(train_df.code, nlp)\n",
    "test_df = sample_test[~sample_test.code.isna()].sample(\n",
    "    round(len(sample_test)/4))\n",
    "test_df[\"code_processed\"] = preprocess(test_df.code, nlp)\n",
    "validation_df = sample_validation[~sample_validation.code.isna()].loc[:]\n",
    "validation_df[\"code_processed\"] = preprocess(\n",
    "    validation_df.code, nlp)\n",
    "convert(train_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_train_transformer.spacy', nlp)\n",
    "convert(test_df.loc[:, [\"code_processed\",\n",
    "        \"tag_list\"]], 'code_test_transformer.spacy', nlp)\n",
    "convert(validation_df.loc[:, [\n",
    "        \"code_processed\", \"tag_list\"]], 'code_validation_transformer.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 09:46:03.044001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 09:46:04.556747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 09:46:04.557120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 09:46:04.557277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_code_transformer\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 09:46:08,585] [INFO] Set up nlp object from config\n",
      "[2023-03-17 09:46:09,140] [INFO] Pipeline: ['transformer', 'textcat_multilabel']\n",
      "[2023-03-17 09:46:09,144] [INFO] Created vocabulary\n",
      "[2023-03-17 09:46:09,146] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2023-03-17 09:46:39,178] [INFO] Initialized pipeline components: ['transformer', 'textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_094640-wtyy85vr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-capybara-39\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/wtyy85vr\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  -------------  ----------  ------\n",
      "  0       0           0.00           0.29       45.54    0.46\n",
      "  0     200           2.13          34.79       72.62    0.73\n",
      "  0     400           2.73          26.88       79.66    0.80\n",
      "  0     600           1.13          25.83       81.41    0.81\n",
      "  0     800           3.11          25.24       84.72    0.85\n",
      "  0    1000           1.88          25.70       86.33    0.86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    1200           2.70          22.75       87.56    0.88\n",
      "  0    1400           2.68          22.93       87.81    0.88\n",
      "  0    1600           1.69          22.04       88.79    0.89\n",
      "  0    1800           2.15          19.03       89.63    0.90\n",
      "  0    2000           2.95          20.55       88.85    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    2200           2.35          24.10       88.19    0.88\n",
      "  0    2400           2.77          19.06       91.03    0.91\n",
      "  0    2600           2.43          18.18       89.58    0.90\n",
      "  0    2800           2.37          22.34       90.85    0.91\n",
      "  0    3000           2.95          17.64       89.48    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    3200           3.07          19.51       91.22    0.91\n",
      "  0    3400           2.41          20.36       90.98    0.91\n",
      "  0    3600           1.80          18.19       90.86    0.91\n",
      "  0    3800           1.64          19.33       91.42    0.91\n",
      "  0    4000           3.81          19.12       91.23    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    4200           2.50          17.19       91.21    0.91\n",
      "  0    4400           3.72          19.45       91.50    0.91\n",
      "  0    4600           2.69          17.88       91.88    0.92\n",
      "  0    4800           3.55          17.71       91.53    0.92\n",
      "  0    5000           2.24          18.18       90.69    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    5200           2.82          18.98       91.59    0.92\n",
      "  0    5400           3.11          17.32       92.15    0.92\n",
      "  0    5600           2.19          17.74       92.32    0.92\n",
      "  0    5800           2.97          17.66       91.69    0.92\n",
      "  0    6000           1.03          15.09       92.46    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectTimeout), entering retry loop.\n",
      "  0    6200           3.34          17.20       92.48    0.92\n",
      "  0    6400           2.05          17.83       92.13    0.92\n",
      "  0    6600           2.54          16.10       92.55    0.93\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0    6800           3.49          15.38       92.72    0.93\n",
      "  0    7000           3.09          16.67       92.90    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "  0    7200           2.08          16.63       92.38    0.92\n",
      "  0    7400           2.95          16.06       92.58    0.93\n",
      "  0    7600           2.83          18.23       92.02    0.92\n",
      "  0    7800           2.71          16.89       92.57    0.93\n",
      "  0    8000           3.77          16.95       92.64    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    8200           3.27          15.99       92.98    0.93\n",
      "  0    8400           2.82          16.58       93.13    0.93\n",
      "  0    8600           1.35          13.09       93.09    0.93\n",
      "  0    8800           2.08          15.79       92.99    0.93\n",
      "  0    9000           1.75          14.82       92.85    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    9200           2.99          17.06       92.76    0.93\n",
      "  0    9400           3.16          17.15       93.37    0.93\n",
      "  0    9600           4.22          17.70       93.38    0.93\n",
      "  0    9800           2.68          16.65       92.97    0.93\n",
      "  0   10000           1.22          15.72       92.76    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   10200           1.64          14.85       93.33    0.93\n",
      "  0   10400           2.22          15.76       93.27    0.93\n",
      "  0   10600           2.21          15.22       93.12    0.93\n",
      "  0   10800           2.05          15.99       93.64    0.94\n",
      "  0   11000           2.62          15.47       93.18    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   11200           1.97          14.64       93.39    0.93\n",
      "  0   11400           2.64          15.79       93.52    0.94\n",
      "  0   11600           3.57          16.54       93.62    0.94\n",
      "  0   11800           1.30          15.41       93.73    0.94\n",
      "  0   12000           3.96          16.21       93.74    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   12200           2.35          15.70       93.80    0.94\n",
      "  0   12400           1.71          14.85       93.84    0.94\n",
      "  0   12600           2.67          16.30       93.79    0.94\n",
      "  0   12800           1.69          13.73       93.85    0.94\n",
      "  0   13000           1.97          14.28       93.59    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   13200           2.68          14.93       93.77    0.94\n",
      "  0   13400           1.43          15.27       93.89    0.94\n",
      "  0   13600           1.10          15.16       93.97    0.94\n",
      "  0   13800           2.29          16.16       93.84    0.94\n",
      "  0   14000           1.91          14.70       94.00    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   14200           1.19          14.11       93.89    0.94\n",
      "  0   14400           1.96          14.23       93.99    0.94\n",
      "  0   14600           1.93          14.68       93.89    0.94\n",
      "  0   14800           1.83          14.04       93.91    0.94\n",
      "  0   15000           1.90          15.00       93.95    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   15200           3.24          15.27       93.91    0.94\n",
      "  0   15400           2.09          14.73       93.89    0.94\n",
      "  0   15600           2.65          13.08       94.07    0.94\n",
      "  0   15800           3.19          13.84       94.06    0.94\n",
      "  0   16000           2.08          14.52       94.15    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   16200           2.01          14.23       94.17    0.94\n",
      "  0   16400           2.34          14.41       94.16    0.94\n",
      "  0   16600           1.24          14.85       94.14    0.94\n",
      "  0   16800           1.12          11.93       94.26    0.94\n",
      "  0   17000           2.06          13.88       94.30    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   17200           3.36          14.13       94.42    0.94\n",
      "  0   17400           1.89          14.41       94.38    0.94\n",
      "  0   17600           2.11          13.16       94.30    0.94\n",
      "  0   17800           1.94          13.23       94.31    0.94\n",
      "  0   18000           2.41          12.50       94.30    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   18200           2.50          14.87       94.38    0.94\n",
      "  0   18400           1.19          13.79       94.41    0.94\n",
      "  0   18600           1.42          14.63       94.46    0.94\n",
      "  0   18800           1.68          13.01       94.46    0.94\n",
      "  0   19000           2.84          13.33       94.45    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 4.2s\n",
      "  0   19200           1.98          13.31       94.46    0.94\n",
      "  0   19400           1.77          13.23       94.47    0.94\n",
      "  0   19600           3.62          13.93       94.46    0.94\n",
      "  0   19800           3.40          14.00       94.47    0.94\n",
      "  1   20000           1.96          13.64       94.47    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc ▁▆▇▇▇█▇███▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f ▁▂▄▅▅▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇█▇▇▇███▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p ▁▃▅▆▆▇▇▇█▇████▇▇█▇▇█▇▇▇█▇█▇████████▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r ▆▁▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▆▆▇▇▆▇█▇▇▇█▇▇▇███▇█▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f ▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p ▁▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇█▇████▇▇█▇████▇████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r ▅▁▃▄▅▅▅▆▆▇▆▆▇▆▇▇▇▆▆▇▇▇▇█▇▇█▇▇▇▇███▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score ▁▆▇▇▇█▇███▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel ▁██▇▆▆▆▆▆▆▆▆▅▅▅▆▅▄▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▄▅▄▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer ▁▆▄▅▆▆▆▅▇▅▅▅▃▅▆▆▆▃▆█▄▅▄▇▅▄▅▅▃▄▆▆▅▃▄▄▃▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score ▁▆▇▇▇█▇███▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed █▇▇▇▇▇▅▇▇▇▇▇▇▅▅▆█▅▆▆▆▆▆▆▇███████████▇▇▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.94471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.64677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.74768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.59169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.66833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.7427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.6075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.94471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 13.63768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer 1.95858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.94471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 4295.36026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mradiant-capybara-39\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/wtyy85vr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 240 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_094640-wtyy85vr/logs\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_code_transformer/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_transformer_filled.cfg --output ./output_code_transformer --paths.train ./code_train_transformer.spacy --paths.dev ./code_test_transformer.spacy --gpu-id 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Bert\n",
    "import transformers\n",
    "from transformers import *\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "2.11.0\n",
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105715/105715 [00:42<00:00, 2502.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105715/105715 [02:21<00:00, 749.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = sample_train.loc[:]\n",
    "train_df.fillna(\"\", inplace=True)\n",
    "train_df[\"text_processed\"] = preprocess_transformers(train_df.text, nlp)\n",
    "train_df[\"code_processed\"] = preprocess_transformers(train_df.code, nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import gc\n",
    "del nlp\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    # time1 = time.time()\n",
    "    \n",
    "    for step in tqdm(range(len(sentences)//batch_size)) :\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "\n",
    "    # time2 = np.round(time.time() - time1,0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_text = train_df[train_df.text != \"\"]\n",
    "train_df_code = train_df[train_df.code != \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10571/10571 [04:56<00:00, 35.64it/s]\n",
      "100%|██████████| 8161/8161 [02:53<00:00, 47.00it/s] \n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "text_embedded_use = feature_USE_fct(train_df_text[\"text_processed\"].to_list(), batch_size)\n",
    "code_embedded_use = feature_USE_fct(\n",
    "    train_df_code[\"code_processed\"].to_list(), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "sample_train.tag_list = sample_train.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "sample_test.tag_list = sample_test.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "sample_validation.tag_list = sample_validation.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(sample_train.tag_list.values)\n",
    "y_train_text = mlb.transform(train_df_text.tag_list.values)\n",
    "y_train_text_sets = train_df_text.tag_list.apply(set)\n",
    "y_train_code = mlb.transform(train_df_code.tag_list.values)\n",
    "y_train_code_sets = train_df_code.tag_list.apply(set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[18:56:02] ../src/data/data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (144 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x1fcf49) [0x7f4df63fcf49]\n  [bt] (1) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x209dd2) [0x7f4df6409dd2]\n  [bt] (2) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x20bab0) [0x7f4df640bab0]\n  [bt] (3) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xad) [0x7f4df632997d]\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7f5380bfae2e]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7f5380bf7493]\n  [bt] (6) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa59d) [0x7f53802e859d]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9c2d) [0x7f53802e7c2d]\n  [bt] (8) /bin/python3(_PyObject_MakeTpCall+0x25b) [0x5580abef2f5b]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44992/1868336696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcode_USE_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcode_USE_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_embedded_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m             )\n\u001b[0;32m-> 1471\u001b[0;31m             train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[1;32m   1472\u001b[0m                 \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\n\u001b[1;32m    447\u001b[0m     way.\"\"\"\n\u001b[0;32m--> 448\u001b[0;31m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"hist\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gpu_hist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 return QuantileDMatrix(\n\u001b[0m\u001b[1;32m    904\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m                 )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m   1384\u001b[0m                 )\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m         self._init(\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         )\n\u001b[0;32m-> 1445\u001b[0;31m         \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;31m# delay check_call to throw intermediate exception first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m  \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# Defer the exception in order to return 0 and stop the iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    532\u001b[0m             )\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0minput_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minput_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temporary_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mdispatch_proxy_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             self.proxy.set_info(\n\u001b[0m\u001b[1;32m    529\u001b[0m                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mfeature_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mset_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mset_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \"\"\"\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch_meta_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0mdispatch_meta_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_meta_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_meta_from_numpy\u001b[0;34m(data, field, dtype, handle)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Masked array is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0minterface_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_array_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m     \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGDMatrixSetInfoFromInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterface_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \"\"\"\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [18:56:02] ../src/data/data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (144 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x1fcf49) [0x7f4df63fcf49]\n  [bt] (1) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x209dd2) [0x7f4df6409dd2]\n  [bt] (2) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x20bab0) [0x7f4df640bab0]\n  [bt] (3) /home/aurelien/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xad) [0x7f4df632997d]\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7f5380bfae2e]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7f5380bf7493]\n  [bt] (6) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa59d) [0x7f53802e859d]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9c2d) [0x7f53802e7c2d]\n  [bt] (8) /bin/python3(_PyObject_MakeTpCall+0x25b) [0x5580abef2f5b]\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "text_USE_xgb = XGBClassifier(tree_method=\"hist\")\n",
    "text_USE_xgb.fit(text_embedded_use, y_train_text)\n",
    "\n",
    "code_USE_xgb = XGBClassifier(tree_method=\"hist\")\n",
    "code_USE_xgb.fit(code_embedded_use, y_train_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_text = train_df[sample_validation.text != \"\"]\n",
    "val_df_code = train_df[sample_validation.code != \"\"]\n",
    "y_val_text = mlb.transform(val_df_text.tag_list.values)\n",
    "y_val_text_sets = val_df_text.tag_list.apply(set)\n",
    "y_val_code = mlb.transform(val_df_text.tag_list.values)\n",
    "y_val_code_sets = val_df_text.tag_list.apply(set)\n",
    "y_pred = clf.predict(text_val_tf)\n",
    "print(\"Roc auc for each tag:\")\n",
    "print(list(zip(mlb.classes_, roc_auc_score(y_val, y_pred, average=None))))\n",
    "print(\n",
    "    f\"Text roc auc macro average: {roc_auc_score(y_val, y_pred, average='macro')}\")\n",
    "print(\n",
    "    f\"Jaccard score sample average: {jaccard_score(y_val, y_pred, average='samples')}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14152/14152 [01:45<00:00, 134.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14152/14152 [01:49<00:00, 128.88it/s]\n",
      "100%|██████████| 14152/14152 [02:21<00:00, 99.71it/s] \n",
      "100%|██████████| 14152/14152 [01:40<00:00, 141.46it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_validation = pd.read_csv(\n",
    "    './validation.csv', converters={'tag_set': eval, 'tag_list': eval})\n",
    "sample_validation.text.fillna(\"\", inplace=True)\n",
    "sample_validation.code.fillna(\"\", inplace=True)\n",
    "sample_validation.tag_list = sample_validation.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(sample_validation.tag_list.values)\n",
    "y_sets = sample_validation.tag_list.apply(set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp_trf = spacy.load(\"en_core_web_trf\")\n",
    "val_trf = sample_validation.loc[:]\n",
    "val_trf[\"texts_processed\"] = preprocess_transformers(val_trf.text, nlp_trf)\n",
    "val_trf['codes_processed'] = preprocess_transformers(val_trf.code, nlp_trf)\n",
    "\n",
    "nlp_text = spacy.load(\"./output_transformer/model-best\")\n",
    "nlp_code = spacy.load(\"./output_code_transformer/model-best\")\n",
    "text_cats = []\n",
    "code_cats = []\n",
    "for summary in tqdm(nlp_text.pipe(val_trf[\"texts_processed\"].values), total=len(val_trf)):\n",
    "    text_cats.append(summary.cats)\n",
    "\n",
    "for summary in tqdm(nlp_code.pipe(val_trf[\"codes_processed\"].values), total=len(val_trf)):\n",
    "    code_cats.append(summary.cats)\n",
    "\n",
    "val_trf[\"text_cats\"] = text_cats\n",
    "val_trf[val_trf.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
    "val_trf[\"code_cats\"] = code_cats\n",
    "val_trf[val_trf.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT ONLY\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7692095799440233), ('android', 0.9080808690792053), ('c', 0.8447096161377827), ('c#', 0.8388032570978465), ('c++', 0.7881483148459298), ('css', 0.913996074936601), ('html', 0.8416098388612389), ('ios', 0.8734087727851785), ('iphone', 0.7788454730954467), ('java', 0.7919521783959212), ('javascript', 0.8453633686623323), ('jquery', 0.8498724053753448), ('node.js', 0.8705711658530503), ('objective-c', 0.793235451364751), ('php', 0.8618515050250596), ('python', 0.9013762832571274)]\n",
      "Text roc auc macro average: 0.8419396346698025\n",
      "Jaccard score sample average: 0.6432989447899001\n",
      "CODE ONLY\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7118275048578196), ('android', 0.7014331326810528), ('c', 0.7336554822753112), ('c#', 0.7457083116089966), ('c++', 0.6881793645604458), ('css', 0.7673096924660345), ('html', 0.7189115131655768), ('ios', 0.7489205401739829), ('iphone', 0.7016473996089918), ('java', 0.6927924005318513), ('javascript', 0.7024452194357037), ('jquery', 0.6839158549562087), ('node.js', 0.7737853899124363), ('objective-c', 0.7767151159608128), ('php', 0.7030276624172256), ('python', 0.7855757304342345)]\n",
      "Text roc auc macro average: 0.7272406446904178\n",
      "Jaccard score sample average: 0.44563228485288975\n",
      "UNION\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7798262113621862), ('android', 0.9330728065836219), ('c', 0.8922120884223322), ('c#', 0.8920414414447129), ('c++', 0.8274153773635112), ('css', 0.9329320756170625), ('html', 0.8723851539523848), ('ios', 0.9195890781017123), ('iphone', 0.7783891069069668), ('java', 0.8528925862177742), ('javascript', 0.7874794734603361), ('jquery', 0.7970455825777965), ('node.js', 0.9176468225804905), ('objective-c', 0.8872877432270979), ('php', 0.9119393226526938), ('python', 0.9561560606844766)]\n",
      "Text roc auc macro average: 0.8711444331971973\n",
      "Jaccard score sample average: 0.5794607526447548\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_text = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_trf.text_cats.values]\n",
    "y_pred_code = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_trf.code_cats.values]\n",
    "\n",
    "y_union = [list(set(y_pred_text[i]) | set(y_pred_code[i])) for i in range(len(y_pred_text))]\n",
    "\n",
    "y_pred_text_t = mlb.transform(y_pred_text)\n",
    "y_pred_code_t = mlb.transform(y_pred_code)\n",
    "y_union_t = mlb.transform(y_union)\n",
    "\n",
    "print(\"TEXT ONLY\")\n",
    "evaluate_predictions(y_pred_text_t, mlb)\n",
    "print(\"CODE ONLY\")\n",
    "evaluate_predictions(y_pred_code_t, mlb)\n",
    "print(\"UNION\")\n",
    "evaluate_predictions(y_union_t, mlb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14152/14152 [01:15<00:00, 187.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14152/14152 [01:31<00:00, 155.04it/s]\n",
      "100%|██████████| 14152/14152 [00:05<00:00, 2368.18it/s]\n",
      "100%|██████████| 14152/14152 [00:06<00:00, 2283.60it/s]\n",
      "/tmp/ipykernel_30482/610484677.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_bow[val_bow.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
      "/tmp/ipykernel_30482/610484677.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_bow[val_bow.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp_lg = spacy.load('en_core_web_lg')\n",
    "val_bow = sample_validation.loc[:]\n",
    "val_bow[\"texts_processed\"] = preprocess(val_bow.text, nlp_lg)\n",
    "val_bow['codes_processed'] = preprocess(val_bow.code, nlp_lg)\n",
    "\n",
    "nlp_text = spacy.load(\"./output_BOW/model-best\")\n",
    "nlp_code = spacy.load(\"./output_code_BOW/model-best\")\n",
    "text_cats = []\n",
    "code_cats = []\n",
    "for summary in tqdm(nlp_text.pipe(val_bow[\"texts_processed\"].values), total=len(val_bow)):\n",
    "    text_cats.append(summary.cats)\n",
    "\n",
    "for summary in tqdm(nlp_code.pipe(val_bow[\"codes_processed\"].values), total=len(val_bow)):\n",
    "    code_cats.append(summary.cats)\n",
    "\n",
    "val_bow[\"text_cats\"] = text_cats\n",
    "val_bow[val_bow.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
    "val_bow[\"code_cats\"] = code_cats\n",
    "val_bow[val_bow.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT ONLY\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6488900967782152), ('android', 0.8301444824905723), ('c', 0.7419467792574461), ('c#', 0.7319272956228179), ('c++', 0.7019025172772958), ('css', 0.8399595601095461), ('html', 0.736338138683504), ('ios', 0.7948700679334377), ('iphone', 0.6635471627376747), ('java', 0.7256070039936248), ('javascript', 0.744058014673224), ('jquery', 0.7819770185228876), ('node.js', 0.776855033231991), ('objective-c', 0.646231952979652), ('php', 0.7956970717251355), ('python', 0.8240978956325864)]\n",
      "Text roc auc macro average: 0.7490031307281007\n",
      "Jaccard score sample average: 0.4823629169022046\n",
      "CODE ONLY\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6013185899615637), ('android', 0.7079430036168805), ('c', 0.67738271317357), ('c#', 0.7018641191800484), ('c++', 0.6596744189582685), ('css', 0.7413250204306504), ('html', 0.6589245157521024), ('ios', 0.6677736187345674), ('iphone', 0.5571416184495195), ('java', 0.6612724150810498), ('javascript', 0.684897964392756), ('jquery', 0.636890254178122), ('node.js', 0.734195023353506), ('objective-c', 0.6582794952058915), ('php', 0.6702477210363726), ('python', 0.755062385334667)]\n",
      "Text roc auc macro average: 0.673387054802471\n",
      "Jaccard score sample average: 0.34179335244555703\n",
      "UNION\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7100764463611141), ('android', 0.8956402777867004), ('c', 0.8075645026106525), ('c#', 0.8208440220794215), ('c++', 0.7603099497456873), ('css', 0.8866551980978101), ('html', 0.7908903897117773), ('ios', 0.8485636652786399), ('iphone', 0.6992046576378165), ('java', 0.7976519276058897), ('javascript', 0.8134471852432464), ('jquery', 0.8219679424524168), ('node.js', 0.8581538262345708), ('objective-c', 0.7515602416627912), ('php', 0.8524570375085048), ('python', 0.9123017704626679)]\n",
      "Text roc auc macro average: 0.8142055650299818\n",
      "Jaccard score sample average: 0.5836484494872002\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_text = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_bow.text_cats.values]\n",
    "y_pred_code = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_bow.code_cats.values]\n",
    "\n",
    "y_union = [list(set(y_pred_text[i]) | set(y_pred_code[i])) for i in range(len(y_pred_text))]\n",
    "\n",
    "y_pred_text_t = mlb.transform(y_pred_text)\n",
    "y_pred_code_t = mlb.transform(y_pred_code)\n",
    "y_union_t = mlb.transform(y_union)\n",
    "\n",
    "print(\"TEXT ONLY\")\n",
    "evaluate_predictions(y_pred_text_t, mlb)\n",
    "print(\"CODE ONLY\")\n",
    "evaluate_predictions(y_pred_code_t, mlb)\n",
    "print(\"UNION\")\n",
    "evaluate_predictions(y_union_t, mlb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14152/14152 [00:07<00:00, 1964.54it/s]\n",
      "100%|██████████| 14152/14152 [00:07<00:00, 1949.08it/s]\n",
      "/tmp/ipykernel_30482/308916592.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_tok2vec[val_tok2vec.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
      "/tmp/ipykernel_30482/308916592.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_tok2vec[val_tok2vec.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
     ]
    }
   ],
   "source": [
    "val_tok2vec = val_bow.loc[:]\n",
    "nlp_text = spacy.load(\"./output_tok2vec/model-best\")\n",
    "nlp_code = spacy.load(\"./output_code_tok2vec/model-best\")\n",
    "text_cats = []\n",
    "code_cats = []\n",
    "for summary in tqdm(nlp_text.pipe(val_tok2vec[\"texts_processed\"].values), total=len(val_tok2vec)):\n",
    "    text_cats.append(summary.cats)\n",
    "\n",
    "for summary in tqdm(nlp_code.pipe(val_tok2vec[\"codes_processed\"].values), total=len(val_tok2vec)):\n",
    "    code_cats.append(summary.cats)\n",
    "\n",
    "val_tok2vec[\"text_cats\"] = text_cats\n",
    "val_tok2vec[val_tok2vec.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
    "val_tok2vec[\"code_cats\"] = code_cats\n",
    "val_tok2vec[val_tok2vec.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT ONLY\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6421738546586514), ('android', 0.8807337192195761), ('c', 0.7965499808922081), ('c#', 0.7380627650712426), ('c++', 0.718745238765006), ('css', 0.8528525867491494), ('html', 0.792017609560249), ('ios', 0.7830064177346702), ('iphone', 0.665392220285253), ('java', 0.771801953182504), ('javascript', 0.8119293888438004), ('jquery', 0.832020834035505), ('node.js', 0.8196238383189313), ('objective-c', 0.6038419139093959), ('php', 0.8302391235253427), ('python', 0.8801803381366468)]\n",
      "Text roc auc macro average: 0.7761982364305082\n",
      "Jaccard score sample average: 0.5327480214810627\n",
      "CODE ONLY\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6002668716090207), ('android', 0.7431834972600363), ('c', 0.7388924816042166), ('c#', 0.7260139695923068), ('c++', 0.697964738350655), ('css', 0.807689796929288), ('html', 0.7150599624483918), ('ios', 0.7110989711456355), ('iphone', 0.6276259641200366), ('java', 0.7048169043203596), ('javascript', 0.7214736670564063), ('jquery', 0.675731020901444), ('node.js', 0.7605714176105575), ('objective-c', 0.6920394652924737), ('php', 0.703084495948223), ('python', 0.787992667051833)]\n",
      "Text roc auc macro average: 0.7133441182025553\n",
      "Jaccard score sample average: 0.4106345392877332\n",
      "UNION\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7071332630606684), ('android', 0.9264158191945214), ('c', 0.8632387846210512), ('c#', 0.8433064624297355), ('c++', 0.7872971390774798), ('css', 0.9156345342496812), ('html', 0.8400022468078767), ('ios', 0.8631867008477109), ('iphone', 0.7544810699221645), ('java', 0.8507429362190034), ('javascript', 0.8600965821987901), ('jquery', 0.8678235245968731), ('node.js', 0.8911862094430645), ('objective-c', 0.7589512385247197), ('php', 0.8965824825915981), ('python', 0.9499879063390853)]\n",
      "Text roc auc macro average: 0.8485041812577514\n",
      "Jaccard score sample average: 0.6193729979272659\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_text = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_tok2vec.text_cats.values]\n",
    "y_pred_code = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_tok2vec.code_cats.values]\n",
    "\n",
    "y_union = [list(set(y_pred_text[i]) | set(y_pred_code[i])) for i in range(len(y_pred_text))]\n",
    "\n",
    "y_pred_text_t = mlb.transform(y_pred_text)\n",
    "y_pred_code_t = mlb.transform(y_pred_code)\n",
    "y_union_t = mlb.transform(y_union)\n",
    "\n",
    "print(\"TEXT ONLY\")\n",
    "evaluate_predictions(y_pred_text_t, mlb)\n",
    "print(\"CODE ONLY\")\n",
    "evaluate_predictions(y_pred_code_t, mlb)\n",
    "print(\"UNION\")\n",
    "evaluate_predictions(y_union_t, mlb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
