{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and categorizer tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install - U pip setuptools wheel\n",
    "%pip install tqdm\n",
    "%pip install torch torchvision torchaudio\n",
    "!export CUDA_PATH = \"/opt/nvidia/cuda\"\n",
    "%pip install - U spacy[cuda11X, transformers]\n",
    "%pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:01:55.816882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 11:01:57.369844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 11:01:57.370214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 11:01:57.370365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "^C\n",
      "2023-03-23 11:02:00.119148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 11:02:01.590718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 11:02:01.591114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 11:02:01.591267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_lg -qq\n",
    "!python3 -m spacy download en_core_web_trf -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 12:57:20.438327: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 12:57:21.956116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 12:57:21.956491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 12:57:21.956649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, jaccard_score, f1_score, precision_score, recall_score\n",
    "\n",
    "with open('selected_tags.json', 'r') as openfile:\n",
    "    selected_tags = json.load(openfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_train = pd.read_csv(\n",
    "    './train.csv', converters={'tag_set': eval, 'tag_list': eval})\n",
    "sample_test = pd.read_csv(\n",
    "    './test.csv', converters={'tag_set': eval, 'tag_list': eval})\n",
    "sample_validation = pd.read_csv(\n",
    "    './validation.csv', converters={'tag_set': eval, 'tag_list': eval})\n",
    "\n",
    "sample_validation.text.fillna(\"\", inplace=True)\n",
    "sample_validation.code.fillna(\"\", inplace=True)\n",
    "sample_validation.tag_list = sample_validation.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([selected_tags])\n",
    "y = mlb.transform(sample_validation.tag_list.values)\n",
    "y_sets = sample_validation.tag_list.apply(set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use the GPU, with memory allocations directed via PyTorch.\n",
    "# This prevents out-of-memory errors that would otherwise occur from competing\n",
    "# memory pools.\n",
    "set_gpu_allocator(\"pytorch\")\n",
    "require_gpu(0)\n",
    "\n",
    "\n",
    "def preprocess(texts, nlp):\n",
    "    removal = ['ADV', 'PRON', 'CCONJ', 'PUNCT',\n",
    "               'PART', 'DET', 'ADP', 'SPACE', 'NUM', 'SYM']\n",
    "    tokens = []\n",
    "    cleaned_texts = []\n",
    "    print(\"preprocessing\")\n",
    "    for summary in tqdm(nlp.pipe(texts, disable=[\"tok2vec\"]), total=len(texts)):\n",
    "        question_tokens = []\n",
    "        for token in summary:\n",
    "            if token.pos_ not in removal and not token.is_stop and token.is_alpha:\n",
    "                question_tokens.append(token.lemma_)\n",
    "        cleaned_texts.append(\" \".join(question_tokens))\n",
    "    # question_tokens = [token.lemma_ for token in summary if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "    return cleaned_texts\n",
    "\n",
    "def preprocess_transformers(texts):\n",
    "    tokens = []\n",
    "    removal = [ 'PUNCT', 'SPACE', 'NUM', 'SYM']\n",
    "    cleaned_texts = []\n",
    "    print(\"preprocessing\")\n",
    "    for summary in tqdm(nlp.pipe(texts, disable=[\"transformer\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"]), total=len(texts)):\n",
    "        question_tokens = []\n",
    "        for token in summary:\n",
    "            if token.pos_ not in removal and token.is_alpha and len(question_tokens)<512:\n",
    "                question_tokens.append(token.lower_)\n",
    "        cleaned_texts.append(\" \".join(question_tokens))\n",
    "    # question_tokens = [token.lemma_ for token in summary if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "    return cleaned_texts\n",
    "\n",
    "\n",
    "def convert(data, outfile, nlp):\n",
    "    db = spacy.tokens.DocBin()\n",
    "    docs = []\n",
    "    print(\"converting\")\n",
    "    for doc, labels in tqdm(nlp.pipe(data.values, as_tuples=True), total=len(data)):\n",
    "        for tag in selected_tags:\n",
    "            doc.cats[tag] = tag in labels\n",
    "        db.add(doc)\n",
    "    db.to_disk(outfile)\n",
    "\n",
    "def evaluate_predictions(y_val, y_pred_text, y_pred_code, mlb, model_name):\n",
    "    y_union = (y_pred_text.astype(np.bool_) |\n",
    "               y_pred_code.astype(np.bool_)).astype(np.int_)\n",
    "\n",
    "    y_intersec = (y_pred_text.astype(np.bool_) &\n",
    "                y_pred_code.astype(np.bool_)).astype(np.int_)\n",
    "    results = {\n",
    "        \"text\": {\n",
    "            \"roc_per_tags\": list(\n",
    "                zip(mlb.classes_, roc_auc_score(y_val, y_pred_text, average=None))),\n",
    "            \"roc_macro\": roc_auc_score(y_val, y_pred_text, average='macro'),\n",
    "            \"jaccard_samples\": jaccard_score(y_val, y_pred_text, average='samples'),\n",
    "            \"jaccard_macro\": jaccard_score(y_val, y_pred_text, average='macro'),\n",
    "            \"jaccard_micro\": jaccard_score(y_val, y_pred_text, average='micro'),\n",
    "            \"f1_samples\": f1_score(y_val, y_pred_text, average='samples'),\n",
    "            \"f1_macro\": f1_score(y_val, y_pred_text, average='macro'),\n",
    "            \"f1_micro\": f1_score(y_val, y_pred_text, average='micro'),\n",
    "            \"precision_samples\": precision_score(y_val, y_pred_text, average='samples'),\n",
    "            \"precision_macro\": precision_score(y_val, y_pred_text, average='macro'),\n",
    "            \"precision_micro\": precision_score(y_val, y_pred_text, average='micro'),\n",
    "            \"recall_samples\": recall_score(y_val, y_pred_text, average='samples'),\n",
    "            \"recall_macro\": recall_score(y_val, y_pred_text, average='macro'),\n",
    "            \"recall_micro\": recall_score(y_val, y_pred_text, average='micro'),\n",
    "        },\n",
    "        \"code\": {\n",
    "            \"roc_per_tags\": list(zip(mlb.classes_, roc_auc_score(y_val, y_pred_code, average=None))),\n",
    "            \"roc_macro\": roc_auc_score(y_val, y_pred_code, average='macro'),\n",
    "            \"jaccard_samples\": jaccard_score(y_val, y_pred_code, average='samples'),\n",
    "            \"jaccard_macro\": jaccard_score(y_val, y_pred_code, average='macro'),\n",
    "            \"jaccard_micro\": jaccard_score(y_val, y_pred_code, average='micro'),\n",
    "            \"f1_samples\": f1_score(y_val, y_pred_code, average='samples'),\n",
    "            \"f1_macro\": f1_score(y_val, y_pred_code, average='macro'),\n",
    "            \"f1_micro\": f1_score(y_val, y_pred_code, average='micro'),\n",
    "            \"precision_samples\": precision_score(y_val, y_pred_code, average='samples'),\n",
    "            \"precision_macro\": precision_score(y_val, y_pred_code, average='macro'),\n",
    "            \"precision_micro\": precision_score(y_val, y_pred_code, average='micro'),\n",
    "            \"recall_samples\": recall_score(y_val, y_pred_code, average='samples'),\n",
    "            \"recall_macro\": recall_score(y_val, y_pred_code, average='macro'),\n",
    "            \"recall_micro\": recall_score(y_val, y_pred_code, average='micro'),\n",
    "        },\n",
    "        \"union\": {\n",
    "            \"roc_per_tags\": list(zip(mlb.classes_, roc_auc_score(y_val, y_union, average=None))),\n",
    "            \"roc_macro\": roc_auc_score(y_val, y_union, average='macro'),\n",
    "            \"jaccard_samples\": jaccard_score(y_val, y_union, average='samples'),\n",
    "            \"jaccard_macro\": jaccard_score(y_val, y_union, average='macro'),\n",
    "            \"jaccard_micro\": jaccard_score(y_val, y_union, average='micro'),\n",
    "            \"f1_samples\": f1_score(y_val, y_union, average='samples'),\n",
    "            \"f1_macro\": f1_score(y_val, y_union, average='macro'),\n",
    "            \"f1_micro\": f1_score(y_val, y_union, average='micro'),\n",
    "            \"precision_samples\": precision_score(y_val, y_union, average='samples'),\n",
    "            \"precision_macro\": precision_score(y_val, y_union, average='macro'),\n",
    "            \"precision_micro\": precision_score(y_val, y_union, average='micro'),\n",
    "            \"recall_samples\": recall_score(y_val, y_union, average='samples'),\n",
    "            \"recall_macro\": recall_score(y_val, y_union, average='macro'),\n",
    "            \"recall_micro\": recall_score(y_val, y_union, average='micro'),\n",
    "        },\n",
    "        \"intersection\": {\n",
    "            \"roc_per_tags\": list(zip(mlb.classes_, roc_auc_score(y_val, y_intersec, average=None))),\n",
    "            \"roc_macro\": roc_auc_score(y_val, y_intersec, average='macro'),\n",
    "            \"jaccard_samples\": jaccard_score(y_val, y_intersec, average='samples'),\n",
    "            \"jaccard_macro\": jaccard_score(y_val, y_intersec, average='macro'),\n",
    "            \"jaccard_micro\": jaccard_score(y_val, y_intersec, average='micro'),\n",
    "            \"f1_samples\": f1_score(y_val, y_intersec, average='samples'),\n",
    "            \"f1_macro\": f1_score(y_val, y_intersec, average='macro'),\n",
    "            \"f1_micro\": f1_score(y_val, y_intersec, average='micro'),\n",
    "            \"precision_samples\": precision_score(y_val, y_intersec, average='samples'),\n",
    "            \"precision_macro\": precision_score(y_val, y_intersec, average='macro'),\n",
    "            \"precision_micro\": precision_score(y_val, y_intersec, average='micro'),\n",
    "            \"recall_samples\": recall_score(y_val, y_intersec, average='samples'),\n",
    "            \"recall_macro\": recall_score(y_val, y_intersec, average='macro'),\n",
    "            \"recall_micro\": recall_score(y_val, y_intersec, average='micro'),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for i in [\"text\", \"code\", \"union\", \"intersection\"]:\n",
    "        print(f\"======= {i} ==========\")\n",
    "        print(\"Roc auc for each tag:\")\n",
    "        print(results[i][\"roc_per_tags\"])\n",
    "        print(f\"Roc auc macro average: {results[i]['roc_macro']:.3f}\")\n",
    "        print(\n",
    "            f\"Jaccard score sample average: {results[i]['jaccard_samples']:.3f}\")\n",
    "        print(\n",
    "            f\"Jaccard score macro average: {results[i]['jaccard_macro']:.3f}\")\n",
    "        print(\n",
    "            f\"Jaccard score micro average: {results[i]['jaccard_micro']:.3f}\")\n",
    "        print(\n",
    "            f\"f1 score sample average: {results[i]['f1_samples']:.3f}\")\n",
    "        print(\n",
    "            f\"f1 score macro average: {results[i]['f1_macro']:.3f}\")\n",
    "        print(\n",
    "            f\"f1 score micro average: {results[i]['f1_micro']:.3f}\")\n",
    "        print(\n",
    "            f\"precision score sample average: {results[i]['precision_samples']:.3f}\")\n",
    "        print(\n",
    "            f\"precision score macro average: {results[i]['precision_macro']:.3f}\")\n",
    "        print(\n",
    "            f\"precision score micro average: {results[i]['precision_micro']:.3f}\")\n",
    "        print(\n",
    "            f\"recall score sample average: {results[i]['recall_samples']:.3f}\")\n",
    "        print(\n",
    "            f\"recall score macro average: {results[i]['recall_macro']:.3f}\")\n",
    "        print(\n",
    "            f\"recall score micro average: {results[i]['recall_micro']:.3f}\")\n",
    "\n",
    "    with open(f\"{model_name}_results.json\", \"w\") as outfile:\n",
    "        json.dump(results, outfile)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1c886c0b29443ba24876ee520b8f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7432fe13e4834bb2bfa03ff207951426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f274e16423144e2b9bd40eb161654c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4830e6e1ecb47b2a0cf11a511ce8c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765ed862c082463f8393599e4b80d2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de583767f70f474cac515b24225d6c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.text.isna()].loc[:]\n",
    "train_df[\"text_processed\"] = preprocess(train_df.text, nlp)\n",
    "convert(train_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_train_bow.spacy', nlp)\n",
    "test_df = sample_test[~sample_test.text.isna()].loc[:]\n",
    "test_df[\"text_processed\"] = preprocess(test_df.text, nlp)\n",
    "convert(test_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_test_bow.spacy', nlp)\n",
    "validation_df = sample_validation[~sample_validation.text.isna()].loc[:]\n",
    "validation_df[\"text_processed\"] = preprocess(\n",
    "    validation_df.text, nlp)\n",
    "convert(validation_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_validation_bow.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 12:18:13.716779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 12:18:15.191947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:18:15.192320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:18:15.192476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mâ„¹ Saving to output directory: output_BOW\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 12:18:19,278] [INFO] Set up nlp object from config\n",
      "[2023-03-17 12:18:19,903] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 12:18:19,906] [INFO] Created vocabulary\n",
      "[2023-03-17 12:18:21,924] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 12:18:23,337] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 12:19:07,372] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_121908-yixyk8wd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mautumn-flower-40\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/yixyk8wd\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       54.94    0.55\n",
      "  0     200          24.56       57.63    0.58\n",
      "  0     400          18.37       61.71    0.62\n",
      "  0     600          16.40       66.07    0.66\n",
      "  0     800          16.69       70.49    0.70\n",
      "  0    1000          15.45       74.75    0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 57.8s\n",
      "  0    1200          14.50       77.78    0.78\n",
      "  0    1400          13.89       80.89    0.81\n",
      "  0    1600          13.25       83.26    0.83\n",
      "  0    1800          12.33       85.22    0.85\n",
      "  0    2000          12.37       86.85    0.87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 45.7s\n",
      "  0    2200          11.96       88.07    0.88\n",
      "  0    2400          11.34       89.10    0.89\n",
      "  0    2600          11.05       89.82    0.90\n",
      "  0    2800          10.93       90.21    0.90\n",
      "  0    3000          10.55       90.65    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 63.5s\n",
      "  0    3200          10.40       91.15    0.91\n",
      "  0    3400          10.36       91.45    0.91\n",
      "  0    3600          10.34       91.65    0.92\n",
      "  0    3800           9.93       91.82    0.92\n",
      "  0    4000          10.10       92.03    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 58.2s\n",
      "  0    4200           9.80       92.15    0.92\n",
      "  0    4400           9.95       92.31    0.92\n",
      "  0    4600           9.77       92.46    0.92\n",
      "  0    4800           9.58       92.62    0.93\n",
      "  0    5000           9.68       92.58    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 51.0s\n",
      "  0    5200           9.48       92.69    0.93\n",
      "  0    5400           9.52       92.83    0.93\n",
      "  0    5600           9.49       92.80    0.93\n",
      "  0    5800           9.21       92.87    0.93\n",
      "  0    6000           9.30       93.00    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 68.0s\n",
      "  0    6200           9.30       93.04    0.93\n",
      "  0    6400           9.42       93.04    0.93\n",
      "  1    6600           9.49       93.14    0.93\n",
      "  1    6800           7.94       93.09    0.93\n",
      "  1    7000           8.22       93.09    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 60.5s\n",
      "  1    7200           8.23       93.08    0.93\n",
      "  1    7400           8.16       93.07    0.93\n",
      "  1    7600           8.30       93.10    0.93\n",
      "  1    7800           8.12       93.04    0.93\n",
      "  1    8000           8.13       93.10    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_BOW/model-last)... Done. 38.4s\n",
      "  1    8200           8.13       93.09    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc â–â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f â–‚â–â–â–â–‚â–ƒâ–„â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p â–â–â–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r â–ƒâ–â–â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f â–ƒâ–â–â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p â–â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r â–ƒâ–â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score â–â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel â–â–ˆâ–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score â–â–â–‚â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed â–ˆâ–„â–â–‚â–ƒâ–„â–â–‡â–„â–„â–…â–ƒâ–ˆâ–‡â–…â–„â–„â–†â–†â–‡â–„â–ƒâ–ˆâ–„â–„â–…â–„â–†â–†â–„â–ƒâ–†â–…â–‚â–ƒâ–…â–â–„â–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.93086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.62274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.78301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.5212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.62599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.7812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.52223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.93086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 8.13347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.93086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 126136.12951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mautumn-flower-40\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/yixyk8wd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 80 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_121908-yixyk8wd/logs\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output_BOW/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_BOW.cfg --output ./output_BOW --paths.train ./text_train_bow.spacy --paths.dev ./text_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34edc8b0ea1c4f81a9e59647fbb47d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef5a97aa7074e40a7e7987c500c0c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cd694b5bc34de0b4e1a4c5f187d4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6bb1f4854f43faa30deedbdfb44dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb7c17e0b44dd780cc6747fab4ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161cce72dec748eba5309a2e0c555162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.code.isna()].loc[:]\n",
    "train_df[\"code_processed\"] = preprocess(train_df.code, nlp)\n",
    "convert(train_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_train_bow.spacy', nlp)\n",
    "test_df = sample_test[~sample_test.code.isna()].loc[:]\n",
    "test_df[\"code_processed\"] = preprocess(test_df.code, nlp)\n",
    "convert(test_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_test_bow.spacy', nlp)\n",
    "validation_df = sample_validation[~sample_validation.code.isna()].loc[:]\n",
    "validation_df[\"code_processed\"] = preprocess(\n",
    "    validation_df.code, nlp)\n",
    "convert(validation_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_validation_bow.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 13:35:08.530678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 13:35:10.172390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:35:10.172770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:35:10.172917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mâ„¹ Saving to output directory: output_code_BOW\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 13:35:14,175] [INFO] Set up nlp object from config\n",
      "[2023-03-17 13:35:14,738] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 13:35:14,741] [INFO] Created vocabulary\n",
      "[2023-03-17 13:35:16,832] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 13:35:18,311] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 13:35:53,999] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_133555-pjfmqgkv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgentle-thunder-43\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/pjfmqgkv\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       51.55    0.52\n",
      "  0     200          28.70       66.91    0.67\n",
      "  0     400          19.49       71.67    0.72\n",
      "  0     600          17.49       75.55    0.76\n",
      "  0     800          16.50       78.86    0.79\n",
      "  0    1000          14.75       81.13    0.81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 28.4s\n",
      "  0    1200          13.57       82.89    0.83\n",
      "  0    1400          13.80       84.41    0.84\n",
      "  0    1600          12.52       85.91    0.86\n",
      "  0    1800          12.07       86.99    0.87\n",
      "  0    2000          11.76       87.73    0.88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 71.3s\n",
      "  0    2200          11.37       88.32    0.88\n",
      "  0    2400          11.02       88.95    0.89\n",
      "  0    2600          11.00       89.40    0.89\n",
      "  0    2800          10.88       89.88    0.90\n",
      "  0    3000          10.80       90.22    0.90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 80.1s\n",
      "  0    3200          10.74       90.45    0.90\n",
      "  0    3400          10.44       90.59    0.91\n",
      "  0    3600          10.47       90.72    0.91\n",
      "  0    3800          10.47       90.94    0.91\n",
      "  0    4000          10.11       90.95    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 51.8s\n",
      "  0    4200          10.33       91.15    0.91\n",
      "  0    4400          10.06       91.20    0.91\n",
      "  0    4600          10.14       91.31    0.91\n",
      "  0    4800           9.88       91.32    0.91\n",
      "  1    5000           9.16       91.40    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 72.5s\n",
      "  1    5200           8.97       91.40    0.91\n",
      "  1    5400           8.88       91.43    0.91\n",
      "  1    5600           8.83       91.38    0.91\n",
      "  1    5800           9.11       91.36    0.91\n",
      "  1    6000           9.02       91.37    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 56.3s\n",
      "  1    6200           8.74       91.45    0.91\n",
      "  1    6400           8.96       91.46    0.91\n",
      "  1    6600           8.96       91.40    0.91\n",
      "  1    6800           8.97       91.39    0.91\n",
      "  1    7000           8.89       91.45    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 92.8s\n",
      "  1    7200           8.96       91.35    0.91\n",
      "  1    7400           8.94       91.41    0.91\n",
      "  1    7600           8.82       91.45    0.91\n",
      "  1    7800           9.27       91.46    0.91\n",
      "  1    8000           8.91       91.49    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 74.3s\n",
      "  1    8200           9.00       91.48    0.91\n",
      "  2    8400           7.86       91.49    0.91\n",
      "  2    8600           7.94       91.48    0.91\n",
      "  2    8800           8.08       91.50    0.92\n",
      "  2    9000           8.26       91.50    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 62.5s\n",
      "  2    9200           8.02       91.41    0.91\n",
      "  2    9400           8.11       91.42    0.91\n",
      "  2    9600           8.49       91.39    0.91\n",
      "  2    9800           8.02       91.48    0.91\n",
      "  2   10000           8.29       91.41    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_BOW/model-last)... Done. 44.8s\n",
      "  2   10200           8.41       91.43    0.91\n",
      "  2   10400           8.07       91.36    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 6241.985 MB of 6241.985 MB uploaded (5473.753 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc â–â–„â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f â–â–‚â–ƒâ–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r â–â–â–‚â–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f â–â–â–‚â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r â–â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score â–â–„â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel â–â–ˆâ–†â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score â–â–„â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed â–†â–„â–†â–…â–„â–†â–‡â–‡â–ˆâ–‡â–‡â–†â–„â–…â–„â–…â–…â–„â–…â–…â–„â–„â–„â–…â–…â–„â–…â–‚â–†â–…â–â–„â–„â–†â–‡â–‡â–„â–„â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.91359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.59129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.77576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.48201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.60022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.77825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.48848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.91359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 8.07295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.91359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 107350.40416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mgentle-thunder-43\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/pjfmqgkv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 100 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_133555-pjfmqgkv/logs\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output_code_BOW/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_BOW.cfg --output ./output_code_BOW --paths.train ./code_train_bow.spacy --paths.dev ./code_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [01:16<00:00, 185.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [01:30<00:00, 156.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:05<00:00, 2385.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:06<00:00, 2323.80it/s]\n",
      "/tmp/ipykernel_5298/610484677.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_bow[val_bow.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
      "/tmp/ipykernel_5298/610484677.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_bow[val_bow.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp_lg = spacy.load('en_core_web_lg')\n",
    "val_bow = sample_validation.loc[:]\n",
    "val_bow[\"texts_processed\"] = preprocess(val_bow.text, nlp_lg)\n",
    "val_bow['codes_processed'] = preprocess(val_bow.code, nlp_lg)\n",
    "\n",
    "nlp_text = spacy.load(\"./output_BOW/model-best\")\n",
    "nlp_code = spacy.load(\"./output_code_BOW/model-best\")\n",
    "text_cats = []\n",
    "code_cats = []\n",
    "for summary in tqdm(nlp_text.pipe(val_bow[\"texts_processed\"].values), total=len(val_bow)):\n",
    "    text_cats.append(summary.cats)\n",
    "\n",
    "for summary in tqdm(nlp_code.pipe(val_bow[\"codes_processed\"].values), total=len(val_bow)):\n",
    "    code_cats.append(summary.cats)\n",
    "\n",
    "val_bow[\"text_cats\"] = text_cats\n",
    "val_bow[val_bow.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
    "val_bow[\"code_cats\"] = code_cats\n",
    "val_bow[val_bow.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= text ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6488900967782152), ('android', 0.8301444824905723), ('c', 0.7419467792574461), ('c#', 0.7319272956228179), ('c++', 0.7019025172772958), ('css', 0.8399595601095461), ('html', 0.736338138683504), ('ios', 0.7948700679334377), ('iphone', 0.6635471627376747), ('java', 0.7256070039936248), ('javascript', 0.744058014673224), ('jquery', 0.7819770185228876), ('node.js', 0.776855033231991), ('objective-c', 0.646231952979652), ('php', 0.7956970717251355), ('python', 0.8240978956325864)]\n",
      "Roc auc macro average: 0.749\n",
      "Jaccard score sample average: 0.482\n",
      "Jaccard score macro average: 0.456\n",
      "Jaccard score micro average: 0.451\n",
      "f1 score sample average: 0.529\n",
      "f1 score macro average: 0.617\n",
      "f1 score micro average: 0.622\n",
      "precision score sample average: 0.566\n",
      "precision score macro average: 0.784\n",
      "precision score micro average: 0.784\n",
      "recall score sample average: 0.537\n",
      "recall score macro average: 0.513\n",
      "recall score micro average: 0.515\n",
      "======= code ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6013185899615637), ('android', 0.7079430036168805), ('c', 0.67738271317357), ('c#', 0.7018641191800484), ('c++', 0.6596744189582685), ('css', 0.7413250204306504), ('html', 0.6589245157521024), ('ios', 0.6677736187345674), ('iphone', 0.5571416184495195), ('java', 0.6612724150810498), ('javascript', 0.684897964392756), ('jquery', 0.636890254178122), ('node.js', 0.734195023353506), ('objective-c', 0.6582794952058915), ('php', 0.6702477210363726), ('python', 0.755062385334667)]\n",
      "Roc auc macro average: 0.673\n",
      "Jaccard score sample average: 0.342\n",
      "Jaccard score macro average: 0.326\n",
      "Jaccard score micro average: 0.325\n",
      "f1 score sample average: 0.374\n",
      "f1 score macro average: 0.484\n",
      "f1 score micro average: 0.491\n",
      "precision score sample average: 0.395\n",
      "precision score macro average: 0.767\n",
      "precision score micro average: 0.770\n",
      "recall score sample average: 0.385\n",
      "recall score macro average: 0.358\n",
      "recall score micro average: 0.360\n",
      "======= union ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7100764463611141), ('android', 0.8956402777867004), ('c', 0.8075645026106525), ('c#', 0.8208440220794215), ('c++', 0.7603099497456873), ('css', 0.8866551980978101), ('html', 0.7908903897117773), ('ios', 0.8485636652786399), ('iphone', 0.6992046576378165), ('java', 0.7976519276058897), ('javascript', 0.8134471852432464), ('jquery', 0.8219679424524168), ('node.js', 0.8581538262345708), ('objective-c', 0.7515602416627912), ('php', 0.8524570375085048), ('python', 0.9123017704626679)]\n",
      "Roc auc macro average: 0.814\n",
      "Jaccard score sample average: 0.584\n",
      "Jaccard score macro average: 0.544\n",
      "Jaccard score micro average: 0.537\n",
      "f1 score sample average: 0.643\n",
      "f1 score macro average: 0.696\n",
      "f1 score micro average: 0.699\n",
      "precision score sample average: 0.659\n",
      "precision score macro average: 0.752\n",
      "precision score micro average: 0.749\n",
      "recall score sample average: 0.683\n",
      "recall score macro average: 0.652\n",
      "recall score micro average: 0.655\n",
      "======= intersection ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5401322403786647), ('android', 0.6424472083207524), ('c', 0.6117649898203638), ('c#', 0.6129473927234448), ('c++', 0.601266986489877), ('css', 0.6946293824423864), ('html', 0.6043722647238291), ('ios', 0.6140800213893651), ('iphone', 0.5214841235493777), ('java', 0.5892274914687848), ('javascript', 0.6155087938227334), ('jquery', 0.5968993302485929), ('node.js', 0.6528962303509259), ('objective-c', 0.5529512065227524), ('php', 0.6134877552530034), ('python', 0.6668585105045856)]\n",
      "Roc auc macro average: 0.608\n",
      "Jaccard score sample average: 0.229\n",
      "Jaccard score macro average: 0.214\n",
      "Jaccard score micro average: 0.214\n",
      "f1 score sample average: 0.248\n",
      "f1 score macro average: 0.345\n",
      "f1 score micro average: 0.353\n",
      "precision score sample average: 0.279\n",
      "precision score macro average: 0.871\n",
      "precision score micro average: 0.882\n",
      "recall score sample average: 0.239\n",
      "recall score macro average: 0.220\n",
      "recall score micro average: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_text = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_bow.text_cats.values]\n",
    "y_pred_code = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_bow.code_cats.values]\n",
    "\n",
    "y_pred_text = mlb.transform(y_pred_text)\n",
    "y_pred_code = mlb.transform(y_pred_code)\n",
    "\n",
    "evaluate_predictions(y, y_pred_text, y_pred_code, mlb, \"bow\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tok2Vec with spacy\n",
    "\n",
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 12:20:20.144707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 12:20:21.668324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:20:21.671812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 12:20:21.671976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mâ„¹ Saving to output directory: output_tok2vec\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 12:20:26,230] [INFO] Set up nlp object from config\n",
      "[2023-03-17 12:20:26,836] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 12:20:26,840] [INFO] Created vocabulary\n",
      "[2023-03-17 12:20:29,539] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 12:20:31,331] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 12:21:16,823] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_122118-r70w9wfk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-pond-41\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/r70w9wfk\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.32       48.97    0.49\n",
      "  0     200          18.07       57.48    0.57\n",
      "  0     400          18.30       63.25    0.63\n",
      "  0     600          16.82       69.07    0.69\n",
      "  0     800          16.68       75.60    0.76\n",
      "  0    1000          15.24       80.69    0.81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 77.1s\n",
      "  0    1200          14.59       82.89    0.83\n",
      "  0    1400          14.07       85.01    0.85\n",
      "  0    1600          13.50       86.39    0.86\n",
      "  0    1800          12.69       87.63    0.88\n",
      "  0    2000          12.69       88.68    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 70.2s\n",
      "  0    2200          12.32       89.43    0.89\n",
      "  0    2400          11.57       90.33    0.90\n",
      "  0    2600          11.42       90.74    0.91\n",
      "  0    2800          11.22       90.90    0.91\n",
      "  0    3000          11.03       91.39    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 72.7s\n",
      "  0    3200          10.70       91.59    0.92\n",
      "  0    3400          10.80       91.79    0.92\n",
      "  0    3600          10.73       92.02    0.92\n",
      "  0    3800          10.35       92.03    0.92\n",
      "  0    4000          10.41       91.88    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 87.8s\n",
      "  0    4200          10.23       92.37    0.92\n",
      "  0    4400          10.30       92.29    0.92\n",
      "  0    4600          10.03       92.43    0.92\n",
      "  0    4800           9.99       92.46    0.92\n",
      "  0    5000          10.15       92.48    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 66.8s\n",
      "  0    5200           9.74       92.70    0.93\n",
      "  0    5400           9.84       92.90    0.93\n",
      "  0    5600           9.88       92.84    0.93\n",
      "  0    5800           9.70       92.92    0.93\n",
      "  0    6000           9.72       92.92    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 58.3s\n",
      "  0    6200           9.83       93.06    0.93\n",
      "  0    6400           9.72       93.15    0.93\n",
      "  1    6600           9.78       93.23    0.93\n",
      "  1    6800           8.95       93.05    0.93\n",
      "  1    7000           9.25       93.19    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 45.5s\n",
      "  1    7200           9.15       93.29    0.93\n",
      "  1    7400           9.13       93.46    0.93\n",
      "  1    7600           9.22       93.30    0.93\n",
      "  1    7800           9.15       93.34    0.93\n",
      "  1    8000           9.14       93.48    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 34.0s\n",
      "  1    8200           9.09       93.28    0.93\n",
      "  1    8400           9.36       93.43    0.93\n",
      "  1    8600           8.83       93.63    0.94\n",
      "  1    8800           9.12       93.65    0.94\n",
      "  1    9000           9.29       93.59    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 8.0s\n",
      "  1    9200           9.21       93.49    0.93\n",
      "  1    9400           9.34       93.52    0.94\n",
      "  1    9600           9.14       93.68    0.94\n",
      "  1    9800           8.98       93.62    0.94\n",
      "  1   10000           9.26       93.60    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 5.8s\n",
      "  1   10200           9.18       93.80    0.94\n",
      "  1   10400           8.98       93.63    0.94\n",
      "  1   10600           9.00       93.80    0.94\n",
      "  1   10800           9.01       93.81    0.94\n",
      "  1   11000           9.11       93.64    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.9s\n",
      "  1   11200           8.86       93.76    0.94\n",
      "  1   11400           8.80       93.93    0.94\n",
      "  1   11600           8.95       93.85    0.94\n",
      "  2   11800           8.96       93.77    0.94\n",
      "  2   12000           8.38       93.99    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.8s\n",
      "  2   12200           8.64       93.91    0.94\n",
      "  2   12400           8.44       93.80    0.94\n",
      "  2   12600           8.64       93.79    0.94\n",
      "  2   12800           8.57       93.90    0.94\n",
      "  2   13000           8.49       93.86    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 4.5s\n",
      "  2   13200           8.91       94.01    0.94\n",
      "  2   13400           8.55       93.87    0.94\n",
      "  2   13600           8.60       93.94    0.94\n",
      "  2   13800           8.64       93.92    0.94\n",
      "  2   14000           8.68       94.07    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.9s\n",
      "  2   14200           8.65       94.12    0.94\n",
      "  2   14400           8.58       93.98    0.94\n",
      "  2   14600           8.54       93.94    0.94\n",
      "  2   14800           9.02       93.97    0.94\n",
      "  2   15000           8.63       94.08    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.6s\n",
      "  2   15200           8.63       93.98    0.94\n",
      "  2   15400           8.85       94.09    0.94\n",
      "  2   15600           8.48       94.19    0.94\n",
      "  2   15800           8.56       94.10    0.94\n",
      "  2   16000           8.56       94.23    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.9s\n",
      "  2   16200           8.47       94.11    0.94\n",
      "  2   16400           8.55       94.14    0.94\n",
      "  2   16600           8.64       94.31    0.94\n",
      "  2   16800           8.71       94.20    0.94\n",
      "  3   17000           8.09       94.25    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.5s\n",
      "  3   17200           8.06       94.10    0.94\n",
      "  3   17400           8.15       94.21    0.94\n",
      "  3   17600           7.89       94.22    0.94\n",
      "  3   17800           7.93       94.24    0.94\n",
      "  3   18000           8.34       94.21    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_tok2vec/model-last)... Done. 3.6s\n",
      "  3   18200           7.93       94.18    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc â–â–ƒâ–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f â–‚â–â–‚â–„â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p â–â–ƒâ–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r â–„â–â–â–ƒâ–…â–…â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f â–‚â–â–‚â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p â–â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r â–„â–â–â–ƒâ–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score â–â–ƒâ–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel â–â–ˆâ–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score â–â–ƒâ–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed â–„â–ƒâ–‡â–‡â–‡â–‡â–‡â–â–‡â–†â–‡â–†â–†â–†â–‡â–†â–‡â–ˆâ–†â–‡â–â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.94185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.65763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.76584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.58133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.65988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.76398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.58074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.94185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 7.93265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.94185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 94456.27158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mfearless-pond-41\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/r70w9wfk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 180 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_122118-r70w9wfk/logs\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output_tok2vec/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_tok2vec.cfg --output ./output_tok2vec --paths.train ./text_train_bow.spacy --paths.dev ./text_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 13:34:36.026104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 13:34:37.612346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:34:37.612711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 13:34:37.612871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mâ„¹ Saving to output directory: output_code_tok2vec\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 13:34:42,731] [INFO] Set up nlp object from config\n",
      "[2023-03-17 13:34:43,319] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-03-17 13:34:43,322] [INFO] Created vocabulary\n",
      "[2023-03-17 13:34:45,466] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-03-17 13:34:46,990] [INFO] Finished initializing nlp object\n",
      "[2023-03-17 13:35:22,916] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_133524-x7mll9zs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-salad-42\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/x7mll9zs\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.23       48.30    0.48\n",
      "  0     200          19.16       62.65    0.63\n",
      "  0     400          16.50       71.57    0.72\n",
      "  0     600          15.38       77.15    0.77\n",
      "  0     800          15.09       80.80    0.81\n",
      "  0    1000          13.70       82.69    0.83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 37.5s\n",
      "  0    1200          12.48       83.16    0.83\n",
      "  0    1400          12.50       84.53    0.85\n",
      "  0    1600          11.74       85.02    0.85\n",
      "  0    1800          11.48       85.80    0.86\n",
      "  0    2000          11.67       85.91    0.86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 86.6s\n",
      "  0    2200          11.16       86.86    0.87\n",
      "  0    2400          10.71       87.50    0.88\n",
      "  0    2600          10.58       88.31    0.88\n",
      "  0    2800          10.62       88.67    0.89\n",
      "  0    3000          10.48       88.81    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 58.7s\n",
      "  0    3200          10.49       89.17    0.89\n",
      "  0    3400          10.27       89.21    0.89\n",
      "  0    3600          10.21       89.35    0.89\n",
      "  0    3800          10.27       89.65    0.90\n",
      "  0    4000          10.04       90.07    0.90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 69.5s\n",
      "  0    4200           9.88       90.27    0.90\n",
      "  0    4400           9.83       90.20    0.90\n",
      "  0    4600           9.79       90.72    0.91\n",
      "  0    4800           9.60       90.79    0.91\n",
      "  1    5000           8.93       90.96    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 82.7s\n",
      "  1    5200           9.20       90.63    0.91\n",
      "  1    5400           8.94       90.79    0.91\n",
      "  1    5600           9.17       90.77    0.91\n",
      "  1    5800           9.21       91.10    0.91\n",
      "  1    6000           9.16       91.11    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 59.7s\n",
      "  1    6200           8.90       91.35    0.91\n",
      "  1    6400           8.97       91.24    0.91\n",
      "  1    6600           9.10       91.42    0.91\n",
      "  1    6800           9.09       91.61    0.92\n",
      "  1    7000           9.08       91.56    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 96.3s\n",
      "  1    7200           9.03       91.33    0.91\n",
      "  1    7400           9.04       91.48    0.91\n",
      "  1    7600           9.13       91.53    0.92\n",
      "  1    7800           9.07       91.55    0.92\n",
      "  1    8000           8.84       91.87    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 93.2s\n",
      "  1    8200           8.87       91.75    0.92\n",
      "  2    8400           8.20       92.04    0.92\n",
      "  2    8600           8.20       92.12    0.92\n",
      "  2    8800           8.33       91.98    0.92\n",
      "  2    9000           8.49       92.07    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 51.1s\n",
      "  2    9200           8.26       91.87    0.92\n",
      "  2    9400           8.33       92.11    0.92\n",
      "  2    9600           8.75       91.96    0.92\n",
      "  2    9800           8.37       92.33    0.92\n",
      "  2   10000           8.56       92.15    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 48.4s\n",
      "  2   10200           8.73       92.10    0.92\n",
      "  2   10400           8.51       92.00    0.92\n",
      "  2   10600           8.41       92.01    0.92\n",
      "  2   10800           8.57       92.28    0.92\n",
      "  2   11000           8.41       92.42    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 58.9s\n",
      "  2   11200           8.62       92.50    0.93\n",
      "  2   11400           8.47       92.50    0.93\n",
      "  3   11600           8.44       92.44    0.92\n",
      "  3   11800           7.97       92.39    0.92\n",
      "  3   12000           8.05       92.66    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 39.2s\n",
      "  3   12200           7.96       92.51    0.93\n",
      "  3   12400           7.73       92.60    0.93\n",
      "  3   12600           7.92       92.61    0.93\n",
      "  3   12800           7.86       92.71    0.93\n",
      "  3   13000           8.30       92.58    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 33.7s\n",
      "  3   13200           8.23       92.60    0.93\n",
      "  3   13400           8.10       92.46    0.92\n",
      "  3   13600           7.99       92.47    0.92\n",
      "  3   13800           8.06       92.52    0.93\n",
      "  3   14000           8.28       92.63    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_tok2vec/model-last)... Done. 23.1s\n",
      "  3   14200           8.24       92.70    0.93\n",
      "  3   14400           8.10       92.63    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc â–â–ƒâ–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f â–â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p â–â–ƒâ–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r â–„â–â–ƒâ–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f â–â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p â–â–„â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r â–„â–â–ƒâ–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score â–â–ƒâ–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel â–â–ˆâ–‡â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score â–â–ƒâ–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed â–‡â–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–…â–ˆâ–†â–‡â–‡â–‡â–†â–„â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–†â–„â–…â–‡â–†â–â–„â–„â–…â–„â–‡â–‡â–…â–„â–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.92632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.62838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.75571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.55893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.64971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.75626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.56947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.92632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 8.09935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.92632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 90503.39666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mwise-salad-42\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/x7mll9zs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 140 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_133524-x7mll9zs/logs\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output_code_tok2vec/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_tok2vec.cfg --output ./output_code_tok2vec --paths.train ./code_train_bow.spacy --paths.dev ./code_test_bow.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:06<00:00, 2082.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:07<00:00, 2010.20it/s]\n",
      "/tmp/ipykernel_5298/308916592.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_tok2vec[val_tok2vec.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
      "/tmp/ipykernel_5298/308916592.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_tok2vec[val_tok2vec.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
     ]
    }
   ],
   "source": [
    "val_tok2vec = val_bow.loc[:]\n",
    "nlp_text = spacy.load(\"./output_tok2vec/model-best\")\n",
    "nlp_code = spacy.load(\"./output_code_tok2vec/model-best\")\n",
    "text_cats = []\n",
    "code_cats = []\n",
    "for summary in tqdm(nlp_text.pipe(val_tok2vec[\"texts_processed\"].values), total=len(val_tok2vec)):\n",
    "    text_cats.append(summary.cats)\n",
    "\n",
    "for summary in tqdm(nlp_code.pipe(val_tok2vec[\"codes_processed\"].values), total=len(val_tok2vec)):\n",
    "    code_cats.append(summary.cats)\n",
    "\n",
    "val_tok2vec[\"text_cats\"] = text_cats\n",
    "val_tok2vec[val_tok2vec.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
    "val_tok2vec[\"code_cats\"] = code_cats\n",
    "val_tok2vec[val_tok2vec.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= text ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6421738546586514), ('android', 0.8807337192195761), ('c', 0.7965499808922081), ('c#', 0.7380627650712426), ('c++', 0.718745238765006), ('css', 0.8528525867491494), ('html', 0.792017609560249), ('ios', 0.7830064177346702), ('iphone', 0.665392220285253), ('java', 0.771801953182504), ('javascript', 0.8119293888438004), ('jquery', 0.832020834035505), ('node.js', 0.8196238383189313), ('objective-c', 0.6038419139093959), ('php', 0.8302391235253427), ('python', 0.8801803381366468)]\n",
      "Roc auc macro average: 0.776\n",
      "Jaccard score sample average: 0.533\n",
      "Jaccard score macro average: 0.486\n",
      "Jaccard score micro average: 0.483\n",
      "f1 score sample average: 0.585\n",
      "f1 score macro average: 0.641\n",
      "f1 score micro average: 0.652\n",
      "precision score sample average: 0.613\n",
      "precision score macro average: 0.754\n",
      "precision score micro average: 0.744\n",
      "recall score sample average: 0.605\n",
      "recall score macro average: 0.574\n",
      "recall score micro average: 0.580\n",
      "======= code ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6002668716090207), ('android', 0.7431834972600363), ('c', 0.7388924816042166), ('c#', 0.7260139695923068), ('c++', 0.697964738350655), ('css', 0.807689796929288), ('html', 0.7150599624483918), ('ios', 0.7110989711456355), ('iphone', 0.6276259641200366), ('java', 0.7048169043203596), ('javascript', 0.7214736670564063), ('jquery', 0.675731020901444), ('node.js', 0.7605714176105575), ('objective-c', 0.6920394652924737), ('php', 0.703084495948223), ('python', 0.787992667051833)]\n",
      "Roc auc macro average: 0.713\n",
      "Jaccard score sample average: 0.411\n",
      "Jaccard score macro average: 0.382\n",
      "Jaccard score micro average: 0.381\n",
      "f1 score sample average: 0.451\n",
      "f1 score macro average: 0.546\n",
      "f1 score micro average: 0.552\n",
      "precision score sample average: 0.469\n",
      "precision score macro average: 0.724\n",
      "precision score micro average: 0.722\n",
      "recall score sample average: 0.470\n",
      "recall score macro average: 0.445\n",
      "recall score micro average: 0.447\n",
      "======= union ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7071332630606684), ('android', 0.9264158191945214), ('c', 0.8632387846210512), ('c#', 0.8433064624297355), ('c++', 0.7872971390774798), ('css', 0.9156345342496812), ('html', 0.8400022468078767), ('ios', 0.8631867008477109), ('iphone', 0.7544810699221645), ('java', 0.8507429362190034), ('javascript', 0.8600965821987901), ('jquery', 0.8678235245968731), ('node.js', 0.8911862094430645), ('objective-c', 0.7589512385247197), ('php', 0.8965824825915981), ('python', 0.9499879063390853)]\n",
      "Roc auc macro average: 0.849\n",
      "Jaccard score sample average: 0.619\n",
      "Jaccard score macro average: 0.562\n",
      "Jaccard score micro average: 0.556\n",
      "f1 score sample average: 0.689\n",
      "f1 score macro average: 0.713\n",
      "f1 score micro average: 0.715\n",
      "precision score sample average: 0.684\n",
      "precision score macro average: 0.703\n",
      "precision score micro average: 0.695\n",
      "recall score sample average: 0.762\n",
      "recall score macro average: 0.732\n",
      "recall score micro average: 0.736\n",
      "======= intersection ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5353074632070038), ('android', 0.6975013972850912), ('c', 0.6722036778753735), ('c#', 0.6207702722338139), ('c++', 0.6294128380381812), ('css', 0.7449078494287561), ('html', 0.667075325200764), ('ios', 0.6309186880325948), ('iphone', 0.538537114483125), ('java', 0.62587592128386), ('javascript', 0.6733064737014163), ('jquery', 0.6399283303400758), ('node.js', 0.6890090464864242), ('objective-c', 0.53693014067715), ('php', 0.6367411368819675), ('python', 0.7181850988493946)]\n",
      "Roc auc macro average: 0.641\n",
      "Jaccard score sample average: 0.297\n",
      "Jaccard score macro average: 0.276\n",
      "Jaccard score micro average: 0.277\n",
      "f1 score sample average: 0.322\n",
      "f1 score macro average: 0.418\n",
      "f1 score micro average: 0.434\n",
      "precision score sample average: 0.357\n",
      "precision score macro average: 0.851\n",
      "precision score micro average: 0.858\n",
      "recall score sample average: 0.313\n",
      "recall score macro average: 0.287\n",
      "recall score micro average: 0.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_text = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_tok2vec.text_cats.values]\n",
    "y_pred_code = [[x for x in selected_tags if y[x] > THRESHOLD]\n",
    "               for y in val_tok2vec.code_cats.values]\n",
    "\n",
    "y_pred_text = mlb.transform(y_pred_text)\n",
    "y_pred_code = mlb.transform(y_pred_code)\n",
    "\n",
    "evaluate_predictions(y, y_pred_text, y_pred_code, mlb, \"tok2vec\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBertA with spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /tmp/tmp0lge8o9t/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmp0lge8o9t/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5413/5413 [00:42<00:00, 127.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5322/5322 [01:00<00:00, 87.44it/s] \n"
     ]
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.text.isna()].loc[:]\n",
    "train_df[\"text_processed\"] = preprocess_transformers(train_df.text, nlp)\n",
    "test_df = sample_test[~sample_test.text.isna()].sample(\n",
    "    round(len(sample_test)/4))\n",
    "test_df[\"text_processed\"] = preprocess_transformers(\n",
    "    test_df.text, nlp)\n",
    "validation_df = sample_validation[~sample_validation.text.isna()].loc[:]\n",
    "validation_df[\"text_processed\"] = preprocess_transformers(\n",
    "    validation_df.text, nlp)\n",
    "convert(train_df.loc[:, [\"text_processed\", \"tag_list\"]],\n",
    "        'text_train_transformer.spacy', nlp)\n",
    "convert(test_df.loc[:, [\"text_processed\",\n",
    "        \"tag_list\"]], 'text_test_transformer.spacy', nlp)\n",
    "convert(validation_df.loc[:, [\n",
    "        \"text_processed\", \"tag_list\"]], 'text_validation_transformer.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:03:36.530246: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 16:03:38.978276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:03:38.978632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:03:38.978786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mâ„¹ Saving to output directory: output_transformer\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-16 16:03:44,086] [INFO] Set up nlp object from config\n",
      "[2023-03-16 16:03:44,762] [INFO] Pipeline: ['transformer', 'textcat_multilabel']\n",
      "[2023-03-16 16:03:44,765] [INFO] Created vocabulary\n",
      "[2023-03-16 16:03:44,767] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2023-03-16 16:04:56,451] [INFO] Initialized pipeline components: ['transformer', 'textcat_multilabel']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['transformer', 'textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230316_160457-ogpumat3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfanciful-haze-34\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/ogpumat3\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  -------------  ----------  ------\n",
      "  0       0           0.00           0.28       47.91    0.48\n",
      "  0     200           3.77          70.76       85.01    0.85\n",
      "  0     400           2.11          44.35       88.98    0.89\n",
      "  0     600           2.23          39.66       90.51    0.91\n",
      "  0     800           2.03          35.19       91.21    0.91\n",
      "  0    1000           2.23          34.45       92.51    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.3s\n",
      "  0    1200           2.10          35.22       93.05    0.93\n",
      "  0    1400           2.05          33.39       93.20    0.93\n",
      "  0    1600           2.06          32.56       93.76    0.94\n",
      "  0    1800           1.89          31.59       93.98    0.94\n",
      "  0    2000           2.03          31.22       93.51    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.9s\n",
      "  0    2200           2.12          32.02       94.10    0.94\n",
      "  0    2400           2.10          30.57       94.44    0.94\n",
      "  0    2600           1.85          29.41       94.55    0.95\n",
      "  0    2800           2.06          30.23       94.55    0.95\n",
      "  0    3000           1.92          29.98       94.71    0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  0    3200           1.88          29.46       94.73    0.95\n",
      "  0    3400           1.99          30.93       94.67    0.95\n",
      "  0    3600           1.99          28.28       95.05    0.95\n",
      "  0    3800           2.02          29.01       94.86    0.95\n",
      "  0    4000           2.07          29.59       95.16    0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.9s\n",
      "  0    4200           1.94          28.87       95.10    0.95\n",
      "  0    4400           2.03          28.86       95.17    0.95\n",
      "  0    4600           1.97          28.41       95.22    0.95\n",
      "  0    4800           1.86          29.83       95.42    0.95\n",
      "  0    5000           2.02          28.35       95.29    0.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  0    5200           2.12          29.23       95.36    0.95\n",
      "  0    5400           2.05          28.68       95.43    0.95\n",
      "  0    5600           1.93          27.78       95.55    0.96\n",
      "  0    5800           2.07          28.37       95.61    0.96\n",
      "  0    6000           1.90          27.20       95.77    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  1    6200           2.03          26.85       95.66    0.96\n",
      "  1    6400           1.86          26.06       95.85    0.96\n",
      "  1    6600           1.79          24.88       95.88    0.96\n",
      "  1    6800           1.85          25.58       95.74    0.96\n",
      "  1    7000           1.83          25.74       95.76    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  1    7200           1.91          25.89       95.88    0.96\n",
      "  1    7400           2.01          25.28       95.87    0.96\n",
      "  1    7600           1.72          24.80       95.80    0.96\n",
      "  1    7800           1.77          24.54       96.05    0.96\n",
      "  1    8000           1.92          25.91       96.00    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  1    8200           2.11          26.44       95.85    0.96\n",
      "  1    8400           1.77          25.99       96.00    0.96\n",
      "  1    8600           1.96          26.13       96.04    0.96\n",
      "  1    8800           1.75          25.36       96.04    0.96\n",
      "  1    9000           1.88          24.59       96.08    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.3s\n",
      "  1    9200           1.98          24.18       96.18    0.96\n",
      "  1    9400           1.85          24.51       96.23    0.96\n",
      "  1    9600           1.88          25.88       96.19    0.96\n",
      "  1    9800           1.92          24.52       96.19    0.96\n",
      "  1   10000           1.88          25.28       96.13    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  1   10200           1.91          24.71       96.30    0.96\n",
      "  1   10400           1.73          24.08       96.17    0.96\n",
      "  1   10600           1.88          24.69       96.18    0.96\n",
      "  1   10800           1.86          24.31       96.30    0.96\n",
      "  1   11000           1.83          23.93       96.30    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  1   11200           1.98          24.48       96.32    0.96\n",
      "  1   11400           1.87          24.74       96.30    0.96\n",
      "  1   11600           1.89          24.77       96.40    0.96\n",
      "  1   11800           1.98          25.97       96.48    0.96\n",
      "  1   12000           1.88          24.12       96.38    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  2   12200           1.78          23.45       96.47    0.96\n",
      "  2   12400           1.70          21.82       96.43    0.96\n",
      "  2   12600           1.79          22.13       96.43    0.96\n",
      "  2   12800           1.74          22.03       96.44    0.96\n",
      "  2   13000           1.64          20.37       96.41    0.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  2   13200           1.82          21.52       96.51    0.97\n",
      "  2   13400           1.75          21.37       96.42    0.96\n",
      "  2   13600           1.88          21.44       96.46    0.96\n",
      "  2   13800           1.73          21.25       96.51    0.97\n",
      "  2   14000           1.70          21.57       96.54    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 3.4s\n",
      "  2   14200           1.67          22.28       96.60    0.97\n",
      "  2   14400           1.70          22.22       96.47    0.96\n",
      "  2   14600           1.93          22.26       96.56    0.97\n",
      "  2   14800           1.52          21.06       96.58    0.97\n",
      "  2   15000           1.64          21.97       96.59    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.7s\n",
      "  2   15200           1.68          21.59       96.57    0.97\n",
      "  2   15400           1.75          21.54       96.60    0.97\n",
      "  2   15600           1.77          21.76       96.67    0.97\n",
      "  2   15800           1.70          20.66       96.62    0.97\n",
      "  2   16000           1.73          21.44       96.65    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  2   16200           1.77          20.71       96.72    0.97\n",
      "  2   16400           1.83          21.27       96.67    0.97\n",
      "  2   16600           1.77          21.01       96.71    0.97\n",
      "  2   16800           1.71          21.35       96.74    0.97\n",
      "  2   17000           1.76          20.40       96.72    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  2   17200           1.69          20.96       96.70    0.97\n",
      "  2   17400           1.57          20.62       96.74    0.97\n",
      "  2   17600           1.78          20.78       96.76    0.97\n",
      "  2   17800           1.61          20.22       96.78    0.97\n",
      "  2   18000           1.85          20.51       96.73    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  3   18200           1.72          20.36       96.74    0.97\n",
      "  3   18400           1.65          18.57       96.73    0.97\n",
      "  3   18600           1.75          18.57       96.75    0.97\n",
      "  3   18800           1.57          18.56       96.72    0.97\n",
      "  3   19000           1.56          17.43       96.72    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_transformer/model-last)... Done. 2.8s\n",
      "  3   19200           1.67          19.07       96.73    0.97\n",
      "  3   19400           1.50          19.57       96.74    0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 9122.831 MB of 9122.852 MB uploaded (23.841 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f â–â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r â–…â–â–ƒâ–„â–…â–†â–…â–†â–‡â–†â–†â–‡â–†â–‡â–†â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p â–â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r â–…â–â–ƒâ–„â–…â–…â–…â–†â–‡â–†â–†â–‡â–†â–‡â–†â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel â–â–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer â–â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed â–…â–„â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–‚â–…â–…â–‡â–„â–„â–…â–…â–â–†â–ˆâ–ˆâ–…â–„â–„â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–†â–‡â–…â–„â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.96736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.74222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.76996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.7207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.73988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.75847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.72218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.96736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 19.57371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer 1.49791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.96736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 11345.44211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mfanciful-haze-34\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/ogpumat3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 228 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230316_160457-ogpumat3/logs\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output_transformer/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_transformer_filled.cfg --output ./output_transformer --paths.train ./text_train_transformer.spacy --paths.dev ./text_test_transformer.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81619/81619 [13:16<00:00, 102.47it/s]\n",
      " 21%|â–ˆâ–ˆ        | 15681/76005 [01:55<07:08, 140.73it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76005/76005 [09:12<00:00, 137.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = sample_train[~sample_train.code.isna()].loc[:]\n",
    "train_df[\"code_processed\"] = preprocess_transformers(train_df.code, nlp)\n",
    "test_df = sample_test[~sample_test.code.isna()].sample(\n",
    "    round(len(sample_test)/4))\n",
    "test_df[\"code_processed\"] = preprocess(test_df.code, nlp)\n",
    "validation_df = sample_validation[~sample_validation.code.isna()].loc[:]\n",
    "validation_df[\"code_processed\"] = preprocess(\n",
    "    validation_df.code, nlp)\n",
    "convert(train_df.loc[:, [\"code_processed\", \"tag_list\"]],\n",
    "        'code_train_transformer.spacy', nlp)\n",
    "convert(test_df.loc[:, [\"code_processed\",\n",
    "        \"tag_list\"]], 'code_test_transformer.spacy', nlp)\n",
    "convert(validation_df.loc[:, [\n",
    "        \"code_processed\", \"tag_list\"]], 'code_validation_transformer.spacy', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 09:46:03.044001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 09:46:04.556747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 09:46:04.557120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 09:46:04.557277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[38;5;4mâ„¹ Saving to output directory: output_code_transformer\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-17 09:46:08,585] [INFO] Set up nlp object from config\n",
      "[2023-03-17 09:46:09,140] [INFO] Pipeline: ['transformer', 'textcat_multilabel']\n",
      "[2023-03-17 09:46:09,144] [INFO] Created vocabulary\n",
      "[2023-03-17 09:46:09,146] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2023-03-17 09:46:39,178] [INFO] Initialized pipeline components: ['transformer', 'textcat_multilabel']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['transformer', 'textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapersonnaz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aurelien/Documents/ocr/OCR_IML_projet5/wandb/run-20230317_094640-wtyy85vr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-capybara-39\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/wtyy85vr\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  -------------  ----------  ------\n",
      "  0       0           0.00           0.29       45.54    0.46\n",
      "  0     200           2.13          34.79       72.62    0.73\n",
      "  0     400           2.73          26.88       79.66    0.80\n",
      "  0     600           1.13          25.83       81.41    0.81\n",
      "  0     800           3.11          25.24       84.72    0.85\n",
      "  0    1000           1.88          25.70       86.33    0.86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    1200           2.70          22.75       87.56    0.88\n",
      "  0    1400           2.68          22.93       87.81    0.88\n",
      "  0    1600           1.69          22.04       88.79    0.89\n",
      "  0    1800           2.15          19.03       89.63    0.90\n",
      "  0    2000           2.95          20.55       88.85    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    2200           2.35          24.10       88.19    0.88\n",
      "  0    2400           2.77          19.06       91.03    0.91\n",
      "  0    2600           2.43          18.18       89.58    0.90\n",
      "  0    2800           2.37          22.34       90.85    0.91\n",
      "  0    3000           2.95          17.64       89.48    0.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    3200           3.07          19.51       91.22    0.91\n",
      "  0    3400           2.41          20.36       90.98    0.91\n",
      "  0    3600           1.80          18.19       90.86    0.91\n",
      "  0    3800           1.64          19.33       91.42    0.91\n",
      "  0    4000           3.81          19.12       91.23    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    4200           2.50          17.19       91.21    0.91\n",
      "  0    4400           3.72          19.45       91.50    0.91\n",
      "  0    4600           2.69          17.88       91.88    0.92\n",
      "  0    4800           3.55          17.71       91.53    0.92\n",
      "  0    5000           2.24          18.18       90.69    0.91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    5200           2.82          18.98       91.59    0.92\n",
      "  0    5400           3.11          17.32       92.15    0.92\n",
      "  0    5600           2.19          17.74       92.32    0.92\n",
      "  0    5800           2.97          17.66       91.69    0.92\n",
      "  0    6000           1.03          15.09       92.46    0.92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectTimeout), entering retry loop.\n",
      "  0    6200           3.34          17.20       92.48    0.92\n",
      "  0    6400           2.05          17.83       92.13    0.92\n",
      "  0    6600           2.54          16.10       92.55    0.93\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0    6800           3.49          15.38       92.72    0.93\n",
      "  0    7000           3.09          16.67       92.90    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "  0    7200           2.08          16.63       92.38    0.92\n",
      "  0    7400           2.95          16.06       92.58    0.93\n",
      "  0    7600           2.83          18.23       92.02    0.92\n",
      "  0    7800           2.71          16.89       92.57    0.93\n",
      "  0    8000           3.77          16.95       92.64    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    8200           3.27          15.99       92.98    0.93\n",
      "  0    8400           2.82          16.58       93.13    0.93\n",
      "  0    8600           1.35          13.09       93.09    0.93\n",
      "  0    8800           2.08          15.79       92.99    0.93\n",
      "  0    9000           1.75          14.82       92.85    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0    9200           2.99          17.06       92.76    0.93\n",
      "  0    9400           3.16          17.15       93.37    0.93\n",
      "  0    9600           4.22          17.70       93.38    0.93\n",
      "  0    9800           2.68          16.65       92.97    0.93\n",
      "  0   10000           1.22          15.72       92.76    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   10200           1.64          14.85       93.33    0.93\n",
      "  0   10400           2.22          15.76       93.27    0.93\n",
      "  0   10600           2.21          15.22       93.12    0.93\n",
      "  0   10800           2.05          15.99       93.64    0.94\n",
      "  0   11000           2.62          15.47       93.18    0.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   11200           1.97          14.64       93.39    0.93\n",
      "  0   11400           2.64          15.79       93.52    0.94\n",
      "  0   11600           3.57          16.54       93.62    0.94\n",
      "  0   11800           1.30          15.41       93.73    0.94\n",
      "  0   12000           3.96          16.21       93.74    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   12200           2.35          15.70       93.80    0.94\n",
      "  0   12400           1.71          14.85       93.84    0.94\n",
      "  0   12600           2.67          16.30       93.79    0.94\n",
      "  0   12800           1.69          13.73       93.85    0.94\n",
      "  0   13000           1.97          14.28       93.59    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   13200           2.68          14.93       93.77    0.94\n",
      "  0   13400           1.43          15.27       93.89    0.94\n",
      "  0   13600           1.10          15.16       93.97    0.94\n",
      "  0   13800           2.29          16.16       93.84    0.94\n",
      "  0   14000           1.91          14.70       94.00    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   14200           1.19          14.11       93.89    0.94\n",
      "  0   14400           1.96          14.23       93.99    0.94\n",
      "  0   14600           1.93          14.68       93.89    0.94\n",
      "  0   14800           1.83          14.04       93.91    0.94\n",
      "  0   15000           1.90          15.00       93.95    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   15200           3.24          15.27       93.91    0.94\n",
      "  0   15400           2.09          14.73       93.89    0.94\n",
      "  0   15600           2.65          13.08       94.07    0.94\n",
      "  0   15800           3.19          13.84       94.06    0.94\n",
      "  0   16000           2.08          14.52       94.15    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   16200           2.01          14.23       94.17    0.94\n",
      "  0   16400           2.34          14.41       94.16    0.94\n",
      "  0   16600           1.24          14.85       94.14    0.94\n",
      "  0   16800           1.12          11.93       94.26    0.94\n",
      "  0   17000           2.06          13.88       94.30    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "  0   17200           3.36          14.13       94.42    0.94\n",
      "  0   17400           1.89          14.41       94.38    0.94\n",
      "  0   17600           2.11          13.16       94.30    0.94\n",
      "  0   17800           1.94          13.23       94.31    0.94\n",
      "  0   18000           2.41          12.50       94.30    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 2.9s\n",
      "  0   18200           2.50          14.87       94.38    0.94\n",
      "  0   18400           1.19          13.79       94.41    0.94\n",
      "  0   18600           1.42          14.63       94.46    0.94\n",
      "  0   18800           1.68          13.01       94.46    0.94\n",
      "  0   19000           2.84          13.33       94.45    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 4.2s\n",
      "  0   19200           1.98          13.31       94.46    0.94\n",
      "  0   19400           1.77          13.23       94.47    0.94\n",
      "  0   19600           3.62          13.93       94.46    0.94\n",
      "  0   19800           3.40          14.00       94.47    0.94\n",
      "  1   20000           1.96          13.64       94.47    0.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output_code_transformer/model-last)... Done. 3.0s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc â–â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f â–â–‚â–„â–…â–…â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r â–†â–â–ƒâ–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f â–â–ƒâ–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p â–â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r â–…â–â–ƒâ–„â–…â–…â–…â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score â–â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel â–â–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–†â–…â–„â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–„â–…â–„â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer â–â–†â–„â–…â–†â–†â–†â–…â–‡â–…â–…â–…â–ƒâ–…â–†â–†â–†â–ƒâ–†â–ˆâ–„â–…â–„â–‡â–…â–„â–…â–…â–ƒâ–„â–†â–†â–…â–ƒâ–„â–„â–ƒâ–„â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score â–â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed â–ˆâ–‡â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–…â–…â–†â–ˆâ–…â–†â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          cats_macro_auc 0.94471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_f 0.64677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_p 0.74768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_macro_r 0.59169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_f 0.66833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_p 0.7427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            cats_micro_r 0.6075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              cats_score 0.94471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         cats_score_desc macro AUC\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss_textcat_multilabel 13.63768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss_transformer 1.95858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   score 0.94471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   speed 4295.36026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               token_acc 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_f 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_p 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 token_r 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mradiant-capybara-39\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/apersonnaz/my_spacy_project/runs/wtyy85vr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 240 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230317_094640-wtyy85vr/logs\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output_code_transformer/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config_transformer_filled.cfg --output ./output_code_transformer --paths.train ./code_train_transformer.spacy --paths.dev ./code_test_transformer.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:07<00:00, 1920.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:20<00:00, 691.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# del nlp_trf\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "val_trf = sample_validation.loc[:]\n",
    "val_trf[\"texts_processed\"] = preprocess_transformers(val_trf.text)\n",
    "val_trf['codes_processed'] = preprocess_transformers(val_trf.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [02:18<00:00, 102.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [01:34<00:00, 149.79it/s]\n",
      "/tmp/ipykernel_5298/1299934847.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_trf[val_trf.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
      "/tmp/ipykernel_5298/1299934847.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_trf[val_trf.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp_text = spacy.load(\"./output_transformer/model-best\")\n",
    "nlp_code = spacy.load(\"./output_code_transformer/model-best\")\n",
    "text_cats = []\n",
    "code_cats = []\n",
    "for summary in tqdm(nlp_text.pipe(val_trf[\"texts_processed\"].values), total=len(val_trf)):\n",
    "    text_cats.append(summary.cats)\n",
    "\n",
    "for summary in tqdm(nlp_code.pipe(val_trf[\"codes_processed\"].values), total=len(val_trf)):\n",
    "    code_cats.append(summary.cats)\n",
    "\n",
    "val_trf[\"text_cats\"] = text_cats\n",
    "val_trf[val_trf.text == \"\"].text_cats = dict.fromkeys(selected_tags, 0)\n",
    "val_trf[\"code_cats\"] = code_cats\n",
    "val_trf[val_trf.code == \"\"].code_cats = dict.fromkeys(selected_tags, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= text ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7692095799440233), ('android', 0.9080808690792053), ('c', 0.8447096161377827), ('c#', 0.8388032570978465), ('c++', 0.7881483148459298), ('css', 0.913996074936601), ('html', 0.8416098388612389), ('ios', 0.8734087727851785), ('iphone', 0.7788454730954467), ('java', 0.7919521783959212), ('javascript', 0.8453633686623323), ('jquery', 0.8498724053753448), ('node.js', 0.8705711658530503), ('objective-c', 0.793235451364751), ('php', 0.8618515050250596), ('python', 0.9013762832571274)]\n",
      "Roc auc macro average: 0.842\n",
      "Jaccard score sample average: 0.643\n",
      "Jaccard score macro average: 0.585\n",
      "Jaccard score micro average: 0.577\n",
      "f1 score sample average: 0.700\n",
      "f1 score macro average: 0.733\n",
      "f1 score micro average: 0.732\n",
      "precision score sample average: 0.715\n",
      "precision score macro average: 0.764\n",
      "precision score micro average: 0.752\n",
      "recall score sample average: 0.735\n",
      "recall score macro average: 0.709\n",
      "recall score micro average: 0.713\n",
      "======= code ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7118275048578196), ('android', 0.7014331326810528), ('c', 0.7336554822753112), ('c#', 0.7457083116089966), ('c++', 0.6881793645604458), ('css', 0.7673096924660345), ('html', 0.7189115131655768), ('ios', 0.7489205401739829), ('iphone', 0.7016473996089918), ('java', 0.6927924005318513), ('javascript', 0.7024452194357037), ('jquery', 0.6839158549562087), ('node.js', 0.7737853899124363), ('objective-c', 0.7767151159608128), ('php', 0.7030276624172256), ('python', 0.7855757304342345)]\n",
      "Roc auc macro average: 0.727\n",
      "Jaccard score sample average: 0.446\n",
      "Jaccard score macro average: 0.370\n",
      "Jaccard score micro average: 0.309\n",
      "f1 score sample average: 0.499\n",
      "f1 score macro average: 0.530\n",
      "f1 score micro average: 0.472\n",
      "precision score sample average: 0.501\n",
      "precision score macro average: 0.643\n",
      "precision score micro average: 0.419\n",
      "recall score sample average: 0.551\n",
      "recall score macro average: 0.535\n",
      "recall score micro average: 0.542\n",
      "======= union ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7798262113621862), ('android', 0.9330728065836219), ('c', 0.8922120884223322), ('c#', 0.8920414414447129), ('c++', 0.8274153773635112), ('css', 0.9329320756170625), ('html', 0.8723851539523848), ('ios', 0.9195890781017123), ('iphone', 0.7783891069069668), ('java', 0.8528925862177742), ('javascript', 0.7874794734603361), ('jquery', 0.7970455825777965), ('node.js', 0.9176468225804905), ('objective-c', 0.8872877432270979), ('php', 0.9119393226526938), ('python', 0.9561560606844766)]\n",
      "Roc auc macro average: 0.871\n",
      "Jaccard score sample average: 0.579\n",
      "Jaccard score macro average: 0.549\n",
      "Jaccard score micro average: 0.443\n",
      "f1 score sample average: 0.668\n",
      "f1 score macro average: 0.686\n",
      "f1 score micro average: 0.614\n",
      "precision score sample average: 0.613\n",
      "precision score macro average: 0.625\n",
      "precision score micro average: 0.484\n",
      "recall score sample average: 0.859\n",
      "recall score macro average: 0.838\n",
      "recall score micro average: 0.842\n",
      "======= intersection ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7012108734396568), ('android', 0.6764411951766363), ('c', 0.6861530099907617), ('c#', 0.6924701272621302), ('c++', 0.6489123020428644), ('css', 0.748373691785573), ('html', 0.6881361980744307), ('ios', 0.702740234857449), ('iphone', 0.7021037657974716), ('java', 0.6318519927099985), ('javascript', 0.7603291146377), ('jquery', 0.7367426777537568), ('node.js', 0.7267097331849963), ('objective-c', 0.6826628240984661), ('php', 0.6529398447895913), ('python', 0.7307959530068854)]\n",
      "Roc auc macro average: 0.698\n",
      "Jaccard score sample average: 0.397\n",
      "Jaccard score macro average: 0.375\n",
      "Jaccard score micro average: 0.379\n",
      "f1 score sample average: 0.435\n",
      "f1 score macro average: 0.542\n",
      "f1 score micro average: 0.550\n",
      "precision score sample average: 0.480\n",
      "precision score macro average: 0.854\n",
      "precision score micro average: 0.824\n",
      "recall score sample average: 0.426\n",
      "recall score macro average: 0.406\n",
      "recall score micro average: 0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_text = [[x for x in mlb.classes_ if y[x] > THRESHOLD]\n",
    "               for y in val_trf.text_cats.values]\n",
    "y_pred_code = [[x for x in mlb.classes_ if y[x] > THRESHOLD]\n",
    "               for y in val_trf.code_cats.values]\n",
    "\n",
    "y_pred_text = mlb.transform(y_pred_text)\n",
    "y_pred_code = mlb.transform(y_pred_code)\n",
    "evaluate_predictions(y, y_pred_text, y_pred_code, mlb, \"roberta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE tensorflow hub with XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Bert\n",
    "import transformers\n",
    "from transformers import *\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "2.11.0\n",
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /tmp/tmpw5sk5l2p/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmpw5sk5l2p/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105715/105715 [00:39<00:00, 2670.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105715/105715 [02:13<00:00, 789.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = sample_train.loc[:]\n",
    "train_df.fillna(\"\", inplace=True)\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "train_df[\"text_processed\"] = preprocess_transformers(train_df.text)\n",
    "train_df[\"code_processed\"] = preprocess_transformers(train_df.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import gc\n",
    "del nlp\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 11:35:56.801813: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 11:35:56.802877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 11:35:56.803093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 11:35:56.803247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 11:35:56.804629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 11:35:56.805444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 11:35:56.805606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 11:35:56.806017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5947 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:1f:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    # time1 = time.time()\n",
    "    \n",
    "    for step in tqdm(range(len(sentences)//batch_size+1)):\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "\n",
    "    # time2 = np.round(time.time() - time1,0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10572 [00:00<?, ?it/s]2023-03-24 11:36:02.647920: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10572/10572 [04:15<00:00, 41.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10572/10572 [03:58<00:00, 44.30it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "text_embedded_use = feature_USE_fct(train_df[\"text_processed\"].to_list(), batch_size)\n",
    "code_embedded_use = feature_USE_fct(\n",
    "    train_df[\"code_processed\"].to_list(), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "sample_train.tag_list = sample_train.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "sample_test.tag_list = sample_test.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "sample_validation.tag_list = sample_validation.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([selected_tags])\n",
    "y_train = mlb.transform(sample_train.tag_list.values)\n",
    "y_train_sets = sample_train.tag_list.apply(set)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "text_USE_xgb = XGBClassifier(tree_method=\"hist\")\n",
    "text_USE_xgb.fit(text_embedded_use, y_train)\n",
    "\n",
    "code_USE_xgb = XGBClassifier(tree_method=\"hist\")\n",
    "code_USE_xgb.fit(code_embedded_use, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /tmp/tmpmof4ljh4/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmpmof4ljh4/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:07<00:00, 2009.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:20<00:00, 705.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1416/1416 [00:11<00:00, 121.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1416/1416 [00:09<00:00, 148.35it/s]\n"
     ]
    }
   ],
   "source": [
    "val_df = sample_validation.loc[:]\n",
    "val_df.fillna(\"\", inplace=True)\n",
    "\n",
    "val_df[\"text_processed\"] = preprocess_transformers(val_df.text)\n",
    "val_df[\"code_processed\"] = preprocess_transformers(val_df.code)\n",
    "y_val = mlb.transform(val_df.tag_list.values)\n",
    "y_val_sets = val_df.tag_list.apply(set)\n",
    "del nlp\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "val_text_embedded_use = feature_USE_fct(\n",
    "    val_df[\"text_processed\"].to_list(), batch_size)\n",
    "val_code_embedded_use = feature_USE_fct(\n",
    "    val_df[\"code_processed\"].to_list(), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= text ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7107239633526663), ('android', 0.8700043685235033), ('c', 0.7827564059236664), ('c#', 0.7836018165712239), ('c++', 0.7473922345302628), ('css', 0.861133560481318), ('html', 0.7650384127319926), ('ios', 0.8212102569036673), ('iphone', 0.6956288338390058), ('java', 0.7698136417099929), ('javascript', 0.7933065634579138), ('jquery', 0.7977869554959579), ('node.js', 0.7811972508080217), ('objective-c', 0.707509145015619), ('php', 0.8167827181628585), ('python', 0.8670704928404472)]\n",
      "Roc auc macro average: 0.786\n",
      "Jaccard score sample average: 0.549\n",
      "Jaccard score macro average: 0.500\n",
      "Jaccard score micro average: 0.495\n",
      "f1 score sample average: 0.603\n",
      "f1 score macro average: 0.660\n",
      "f1 score micro average: 0.663\n",
      "precision score sample average: 0.632\n",
      "precision score macro average: 0.748\n",
      "precision score micro average: 0.743\n",
      "recall score sample average: 0.623\n",
      "recall score macro average: 0.593\n",
      "recall score micro average: 0.598\n",
      "======= code ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.6078022528489112), ('android', 0.7218158281885403), ('c', 0.7016342873715631), ('c#', 0.72292088495904), ('c++', 0.6932077152914522), ('css', 0.7703510866055336), ('html', 0.6937346215642372), ('ios', 0.7255155604855534), ('iphone', 0.5780951385762861), ('java', 0.6944208918433556), ('javascript', 0.7066374789755923), ('jquery', 0.6687650766289982), ('node.js', 0.7263563735410054), ('objective-c', 0.7164001207264499), ('php', 0.6895696990437606), ('python', 0.7718535621376521)]\n",
      "Roc auc macro average: 0.699\n",
      "Jaccard score sample average: 0.390\n",
      "Jaccard score macro average: 0.365\n",
      "Jaccard score micro average: 0.365\n",
      "f1 score sample average: 0.428\n",
      "f1 score macro average: 0.528\n",
      "f1 score micro average: 0.535\n",
      "precision score sample average: 0.451\n",
      "precision score macro average: 0.738\n",
      "precision score micro average: 0.738\n",
      "recall score sample average: 0.440\n",
      "recall score macro average: 0.415\n",
      "recall score micro average: 0.419\n",
      "======= union ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.7592107240915484), ('android', 0.9162881683680354), ('c', 0.8436342647283043), ('c#', 0.8540479800917783), ('c++', 0.7997807665113167), ('css', 0.908539585306271), ('html', 0.817674059305654), ('ios', 0.8858055381062826), ('iphone', 0.7462448708741103), ('java', 0.8308412203199461), ('javascript', 0.8451981956700063), ('jquery', 0.8475233401865289), ('node.js', 0.8564002153126109), ('objective-c', 0.8284250801879254), ('php', 0.8801932909066622), ('python', 0.9339253417999522)]\n",
      "Roc auc macro average: 0.847\n",
      "Jaccard score sample average: 0.624\n",
      "Jaccard score macro average: 0.567\n",
      "Jaccard score micro average: 0.560\n",
      "f1 score sample average: 0.692\n",
      "f1 score macro average: 0.718\n",
      "f1 score micro average: 0.718\n",
      "precision score sample average: 0.690\n",
      "precision score macro average: 0.712\n",
      "precision score micro average: 0.705\n",
      "recall score sample average: 0.757\n",
      "recall score macro average: 0.727\n",
      "recall score micro average: 0.731\n",
      "======= intersection ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5593154921100292), ('android', 0.6755320283440085), ('c', 0.6407564285669249), ('c#', 0.6524747214384856), ('c++', 0.6408191833103982), ('css', 0.7229450617805807), ('html', 0.641098974990576), ('ios', 0.6609202792829382), ('iphone', 0.5274791015411816), ('java', 0.6333933132334024), ('javascript', 0.6547458467634999), ('jquery', 0.6190286919384271), ('node.js', 0.6511534090364162), ('objective-c', 0.5954841855541435), ('php', 0.626159126299957), ('python', 0.7049987131781472)]\n",
      "Roc auc macro average: 0.638\n",
      "Jaccard score sample average: 0.292\n",
      "Jaccard score macro average: 0.270\n",
      "Jaccard score micro average: 0.273\n",
      "f1 score sample average: 0.318\n",
      "f1 score macro average: 0.416\n",
      "f1 score micro average: 0.428\n",
      "precision score sample average: 0.356\n",
      "precision score macro average: 0.846\n",
      "precision score micro average: 0.852\n",
      "recall score sample average: 0.307\n",
      "recall score macro average: 0.281\n",
      "recall score micro average: 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_text = text_USE_xgb.predict(val_text_embedded_use)\n",
    "y_pred_code = code_USE_xgb.predict(val_code_embedded_use)\n",
    "\n",
    "evaluate_predictions(y_val, y_pred_text, y_pred_code, mlb, \"use\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta HuggingFace with XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105715/105715 [00:41<00:00, 2545.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105715/105715 [02:16<00:00, 772.66it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "train_df = sample_train.loc[:]\n",
    "train_df.fillna(\"\", inplace=True)\n",
    "train_df[\"text_processed\"] = preprocess_transformers(train_df.text)\n",
    "train_df[\"code_processed\"] = preprocess_transformers(train_df.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_text = train_df[train_df.text_processed != \"\"].loc[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:29:11.010007: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 16:29:11.010675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 16:29:11.010891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 16:29:11.011045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 16:29:11.011375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 16:29:11.011650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 16:29:11.012176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 16:29:11.012457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4883 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:1f:00.0, compute capability: 7.5\n",
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "model = TFRobertaModel.from_pretrained('roberta-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_Roberta_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    # time1 = time.time()\n",
    "    features = None\n",
    "    for step in tqdm(range(len(sentences)//batch_size+1)):\n",
    "        idx = step*batch_size\n",
    "        tensors = tokenizer(sentences[idx:idx+batch_size], return_tensors='tf', padding=True,truncation=True)\n",
    "        outputs = model(tensors)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        batch_features = np.array(last_hidden_states).mean(axis=1)\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.concatenate([features, batch_features])\n",
    "\n",
    "    # time2 = np.round(time.time() - time1,0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10572/10572 [1:25:40<00:00,  2.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10572/10572 [1:14:48<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "text_embedded_roberta = feature_Roberta_fct(\n",
    "    train_df[\"text_processed\"].to_list(), batch_size)\n",
    "code_embedded_roberta = feature_Roberta_fct(\n",
    "    train_df[\"code_processed\"].to_list(), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./roberta_train_text_embed.npy', text_embedded_roberta)\n",
    "np.save('./roberta_train_code_embed.npy', code_embedded_roberta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "sample_train.tag_list = sample_train.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "sample_test.tag_list = sample_test.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "sample_validation.tag_list = sample_validation.tag_list.apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in selected_tags])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([selected_tags])\n",
    "y_train = mlb.transform(sample_train.tag_list.values)\n",
    "y_train_sets = sample_train.tag_list.apply(set)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "text_roberta_xgb = XGBClassifier(tree_method=\"hist\")\n",
    "text_roberta_xgb.fit(text_embedded_roberta, y_train)\n",
    "\n",
    "code_roberta_xgb = XGBClassifier(tree_method=\"hist\")\n",
    "code_roberta_xgb.fit(code_embedded_roberta, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:04<00:00, 2979.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14152/14152 [00:17<00:00, 824.16it/s] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44434/120180252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_val_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "val_df = sample_validation.loc[:]\n",
    "val_df.fillna(\"\", inplace=True)\n",
    "\n",
    "val_df[\"text_processed\"] = preprocess_transformers(val_df.text)\n",
    "val_df[\"code_processed\"] = preprocess_transformers(val_df.code)\n",
    "y_val = mlb.transform(val_df.tag_list.values)\n",
    "y_val_sets = val_df.tag_list.apply(set)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1416/1416 [10:46<00:00,  2.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1416/1416 [09:21<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_text_embedded_roberta = feature_Roberta_fct(\n",
    "    val_df[\"text_processed\"].to_list(), batch_size)\n",
    "val_code_embedded_roberta = feature_Roberta_fct(\n",
    "    val_df[\"code_processed\"].to_list(), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= text ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5323535435082127), ('android', 0.6626565762339472), ('c', 0.6828096040229613), ('c#', 0.552334829047802), ('c++', 0.6239461723852171), ('css', 0.7829796975824226), ('html', 0.6796912837133751), ('ios', 0.6458077954614209), ('iphone', 0.591707405666083), ('java', 0.5609867626582026), ('javascript', 0.6522539819979319), ('jquery', 0.6634266860546297), ('node.js', 0.6387525535404298), ('objective-c', 0.5553907087146605), ('php', 0.6169504685277717), ('python', 0.6357380178577778)]\n",
      "Roc auc macro average: 0.630\n",
      "Jaccard score sample average: 0.242\n",
      "Jaccard score macro average: 0.239\n",
      "Jaccard score micro average: 0.242\n",
      "f1 score sample average: 0.273\n",
      "f1 score macro average: 0.374\n",
      "f1 score micro average: 0.390\n",
      "precision score sample average: 0.301\n",
      "precision score macro average: 0.638\n",
      "precision score micro average: 0.648\n",
      "recall score sample average: 0.277\n",
      "recall score macro average: 0.276\n",
      "recall score micro average: 0.279\n",
      "======= code ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5420030978515346), ('android', 0.6418505836475886), ('c', 0.653263066465354), ('c#', 0.6218703046509704), ('c++', 0.6374889569759221), ('css', 0.7467961172327656), ('html', 0.669510384643231), ('ios', 0.6544089198833206), ('iphone', 0.5527741276742861), ('java', 0.5831494394026773), ('javascript', 0.6498303461950187), ('jquery', 0.6156000077038265), ('node.js', 0.6702567087381435), ('objective-c', 0.6462500917465306), ('php', 0.6028058287493941), ('python', 0.6853394903622148)]\n",
      "Roc auc macro average: 0.636\n",
      "Jaccard score sample average: 0.262\n",
      "Jaccard score macro average: 0.254\n",
      "Jaccard score micro average: 0.257\n",
      "f1 score sample average: 0.291\n",
      "f1 score macro average: 0.397\n",
      "f1 score micro average: 0.409\n",
      "precision score sample average: 0.315\n",
      "precision score macro average: 0.696\n",
      "precision score micro average: 0.699\n",
      "recall score sample average: 0.295\n",
      "recall score macro average: 0.285\n",
      "recall score micro average: 0.289\n",
      "======= union ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5695704831731794), ('android', 0.7459321337025163), ('c', 0.7591520289410676), ('c#', 0.6546136345638118), ('c++', 0.7019823463670162), ('css', 0.8599304724476423), ('html', 0.7567999136688496), ('ios', 0.744820942704811), ('iphone', 0.6387482789432982), ('java', 0.6269183571372082), ('javascript', 0.7346317592427805), ('jquery', 0.7305408567617929), ('node.js', 0.7484424002800504), ('objective-c', 0.6789412673854412), ('php', 0.6871668396736251), ('python', 0.7628129256766202)]\n",
      "Roc auc macro average: 0.713\n",
      "Jaccard score sample average: 0.382\n",
      "Jaccard score macro average: 0.362\n",
      "Jaccard score micro average: 0.365\n",
      "f1 score sample average: 0.432\n",
      "f1 score macro average: 0.523\n",
      "f1 score micro average: 0.535\n",
      "precision score sample average: 0.447\n",
      "precision score macro average: 0.644\n",
      "precision score micro average: 0.644\n",
      "recall score sample average: 0.462\n",
      "recall score macro average: 0.452\n",
      "recall score micro average: 0.457\n",
      "======= intersection ==========\n",
      "Roc auc for each tag:\n",
      "[('.net', 0.5047861581865678), ('android', 0.5585750261790194), ('c', 0.5769206415472478), ('c#', 0.5195914991349605), ('c++', 0.559452782994123), ('css', 0.6698453423675459), ('html', 0.5924017546877565), ('ios', 0.5553957726399307), ('iphone', 0.5057332543970711), ('java', 0.5172178449236714), ('javascript', 0.5674525689501702), ('jquery', 0.5484858369966633), ('node.js', 0.560566861998523), ('objective-c', 0.5226995330757499), ('php', 0.5325894576035406), ('python', 0.5582645825433726)]\n",
      "Roc auc macro average: 0.553\n",
      "Jaccard score sample average: 0.105\n",
      "Jaccard score macro average: 0.106\n",
      "Jaccard score micro average: 0.108\n",
      "f1 score sample average: 0.117\n",
      "f1 score macro average: 0.183\n",
      "f1 score micro average: 0.195\n",
      "precision score sample average: 0.138\n",
      "precision score macro average: 0.821\n",
      "precision score micro average: 0.829\n",
      "recall score sample average: 0.109\n",
      "recall score macro average: 0.109\n",
      "recall score micro average: 0.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelien/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_text = text_roberta_xgb.predict(val_text_embedded_roberta)\n",
    "y_pred_code = code_roberta_xgb.predict(val_code_embedded_roberta)\n",
    "\n",
    "evaluate_predictions(y_val, y_pred_text, y_pred_code, mlb, \"roberta_hf_xgb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
